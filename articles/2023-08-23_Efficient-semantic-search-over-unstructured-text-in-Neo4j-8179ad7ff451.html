<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Efficient semantic search over unstructured text in Neo4j</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Efficient semantic search over unstructured text in Neo4j</h1>
</header>
<section data-field="subtitle" class="p-summary">
Integrate the newly added vector index into LangChain to enhance your RAG applications
</section>
<section data-field="body" class="e-content">
<section name="5735" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="dbd1" id="dbd1" class="graf graf--h3 graf--leading graf--title">Efficient semantic search over unstructured text in Neo4j</h3><h4 name="3b7b" id="3b7b" class="graf graf--h4 graf-after--h3 graf--subtitle">Integrate the newly added vector index into LangChain to enhance your RAG applications</h4><p name="c36d" id="c36d" class="graf graf--p graf-after--h4">Since the advent of ChatGPT six months ago, the technology landscape has undergone a transformative shift. ChatGPT’s exceptional capacity for generalization has diminished the requirement for specialized deep learning teams and extensive training datasets to create custom NLP models. This has democratized access to a range of NLP tasks, such as summarization and information extraction, making them more readily available than ever before. However, we soon realized the <a href="https://medium.com/neo4j/knowledge-graphs-llms-fine-tuning-vs-retrieval-augmented-generation-30e875d63a35" data-href="https://medium.com/neo4j/knowledge-graphs-llms-fine-tuning-vs-retrieval-augmented-generation-30e875d63a35" class="markup--anchor markup--p-anchor" target="_blank">limitations of ChatGPT-like models</a>, such as knowledge date cutoff and not having access to private information. In my opinion, what followed was the second wave of generative AI transformation with the rise of Retrieval Augmented Generation (RAG) applications, where you feed relevant information to the model at query time to construct better and more accurate answers.</p><figure name="aecc" id="aecc" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*e2Z35NXHCtOom3-C5fC8Gg.png" data-width="800" data-height="399" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*e2Z35NXHCtOom3-C5fC8Gg.png"><figcaption class="imageCaption">RAG application flow. Image by the author. Icons from <a href="https://www.flaticon.com/" data-href="https://www.flaticon.com/" class="markup--anchor markup--figure-anchor" rel="nofollow noopener" target="_blank">https://www.flaticon.com/</a></figcaption></figure><p name="a277" id="a277" class="graf graf--p graf-after--figure">As mentioned, the RAG applications require a smart search tool that is able to retrieve additional information based on the user input, which allows the LLMs to produce more accurate and up-to-date answers. At first, the focus was mostly on retrieving information from unstructured text using semantic search. However, it soon became evident that a combination of structured and unstructured data is the best approach to RAG applications if you want to <a href="https://medium.com/neo4j/knowledge-graphs-llms-real-time-graph-analytics-89b392eaaa95" data-href="https://medium.com/neo4j/knowledge-graphs-llms-real-time-graph-analytics-89b392eaaa95" class="markup--anchor markup--p-anchor" target="_blank">move beyond “Chat with your PDF” applications</a>.</p><p name="4c48" id="4c48" class="graf graf--p graf-after--p">Neo4j was and is an excellent fit for handling structured information, but it struggled a bit with semantic search due to its brute-force approach. However, the struggle is in the past as Neo4j has<a href="https://neo4j.com/blog/vector-search-deeper-insights/" data-href="https://neo4j.com/blog/vector-search-deeper-insights/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> introduced a new vector index in version 5.11</a> designed to efficiently perform semantic search over unstructured text or other embedded data modalities. The newly added vector index makes Neo4j a great fit for most RAG applications as it now works great with both structured and unstructured data.</p><p name="3e57" id="3e57" class="graf graf--p graf-after--p">In this blog post I will show you how to setup a vector index in Neo4j and integrate it into the <a href="https://www.langchain.com/" data-href="https://www.langchain.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">LangChain ecosystem</a>. The code is available on <a href="https://github.com/tomasonjo/blogs/blob/master/llm/Neo4j_vector_index_%26_Langchain.ipynb" data-href="https://github.com/tomasonjo/blogs/blob/master/llm/Neo4j_vector_index_%26_Langchain.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GitHub</a>.</p><h4 name="927e" id="927e" class="graf graf--h4 graf-after--p">Neo4j Environment setup</h4><p name="b296" id="b296" class="graf graf--p graf-after--h4">You need to setup a Neo4j 5.11 or greater to follow along with the examples in this blog post. The easiest way is to start a free instance on <a href="https://neo4j.com/cloud/platform/aura-graph-database/" data-href="https://neo4j.com/cloud/platform/aura-graph-database/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Neo4j Aura</a>, which offers cloud instances of Neo4j database. Alternatively, you can also setup a local instance of the Neo4j database by downloading the <a href="https://neo4j.com/download/" data-href="https://neo4j.com/download/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Neo4j Desktop</a> application and creating a local database instance.</p><p name="db6d" id="db6d" class="graf graf--p graf-after--p">After you have instantiated the Neo4j database, you can use the LangChain library to connect to it.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="b1c1" id="b1c1" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">from</span> langchain.graphs <span class="hljs-keyword">import</span> Neo4jGraph<br /><br />NEO4J_URI=<span class="hljs-string">&quot;neo4j+s://1234.databases.neo4j.io&quot;</span><br />NEO4J_USERNAME=<span class="hljs-string">&quot;neo4j&quot;</span><br />NEO4J_PASSWORD=<span class="hljs-string">&quot;-&quot;</span><br /><br />graph = Neo4jGraph(<br />    url=NEO4J_URI,<br />    username=NEO4J_USERNAME,<br />    password=NEO4J_PASSWORD<br />)</span></pre><h4 name="6238" id="6238" class="graf graf--h4 graf-after--pre">Setting up the Vector Index</h4><p name="a9dc" id="a9dc" class="graf graf--p graf-after--h4"><a href="https://neo4j.com/docs/cypher-manual/current/indexes-for-vector-search/" data-href="https://neo4j.com/docs/cypher-manual/current/indexes-for-vector-search/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Neo4j vector index is powered by Lucene</a>, where Lucene implements a Hierarchical Navigable Small World (HNSW) Graph to perform a approximate nearest neighbors (ANN) query over the vector space.</p><p name="191a" id="191a" class="graf graf--p graf-after--p">Neo4j’s implementation of the vector index is designed to index a single node property of a node label. For example, if you wanted to index nodes with the label <code class="markup--code markup--p-code">Chunk</code> on their node property <code class="markup--code markup--p-code">embedding</code> , you would use the following Cypher procedure.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="sql" name="d665" id="d665" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">CALL</span> db.index.vector.createNodeIndex(<br />  <span class="hljs-string">&#x27;wikipedia&#x27;</span>, <span class="hljs-operator">/</span><span class="hljs-operator">/</span> index name<br />  <span class="hljs-string">&#x27;Chunk&#x27;</span>,     <span class="hljs-operator">/</span><span class="hljs-operator">/</span> node label<br />  <span class="hljs-string">&#x27;embedding&#x27;</span>, <span class="hljs-operator">/</span><span class="hljs-operator">/</span> node property<br />   <span class="hljs-number">1536</span>,       <span class="hljs-operator">/</span><span class="hljs-operator">/</span> vector size<br />   <span class="hljs-string">&#x27;cosine&#x27;</span>    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> similarity metric<br />)</span></pre><p name="5920" id="5920" class="graf graf--p graf-after--pre">Along with the index name, node label, and property, you must specify the vector size (embedding dimension), and the similarity metric. We will be using OpenAI’s text-embedding-ada-002 embedding model, which uses vector size <strong class="markup--strong markup--p-strong">1536</strong> to represent text in the embedding space. At the moment, only the <strong class="markup--strong markup--p-strong">cosine</strong> and <strong class="markup--strong markup--p-strong">Euclidean</strong> similarity metrics are available. OpenAI suggests using the cosine similarity metric when using their embedding model.</p><h4 name="e872" id="e872" class="graf graf--h4 graf-after--p">Populating the Vector index</h4><p name="e8c2" id="e8c2" class="graf graf--p graf-after--h4">Neo4j is schema-less by design, which means it doesn’t enforce any restrictions what goes into a node property. For example, the <code class="markup--code markup--p-code">embedding</code> property of the <code class="markup--code markup--p-code">Chunk</code> node could store integers, list of integers or even strings. Let’s try this out.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="013d" id="013d" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">WITH [<span class="hljs-number">1</span>, [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], [<span class="hljs-string">&quot;2&quot;</span>,<span class="hljs-string">&quot;5&quot;</span>], [x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">1535</span>) | toFloat(x)]] AS exampleValues<br />UNWIND <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, size(exampleValues) - <span class="hljs-number">1</span>) <span class="hljs-keyword">as</span> index<br />CREATE (:Chunk {embedding: exampleValues[index], index: index})</span></pre><p name="4f51" id="4f51" class="graf graf--p graf-after--pre">This query creates a <code class="markup--code markup--p-code">Chunk</code>node for each element in the list and uses the element as the <code class="markup--code markup--p-code">embedding</code>property value. For example, the first <code class="markup--code markup--p-code">Chunk</code> node will have the <code class="markup--code markup--p-code">embedding</code> property value <strong class="markup--strong markup--p-strong">1</strong>, the second node <strong class="markup--strong markup--p-strong">[1,2,3]</strong>, and so on. Neo4j doesn’t enforce any rules on what you can store under node properties. However, the vector index has clear instructions about the type of values and their embedding dimension it should index.</p><p name="8639" id="8639" class="graf graf--p graf-after--p">We can test which values were indexed by performing a vector index search.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="less" name="d009" id="d009" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-selector-tag">CALL</span> <span class="hljs-selector-tag">db</span><span class="hljs-selector-class">.index</span><span class="hljs-selector-class">.vector</span><span class="hljs-selector-class">.queryNodes</span>(<br />  <span class="hljs-string">&#x27;wikipedia&#x27;</span>, <span class="hljs-comment">// index name</span><br />   <span class="hljs-number">3</span>, <span class="hljs-comment">// topK neighbors to return</span><br />   [x in <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">1535</span>) | <span class="hljs-built_in">toFloat</span>(x) / <span class="hljs-number">2</span>] <span class="hljs-comment">// input vector</span><br />)<br /><span class="hljs-selector-tag">YIELD</span> <span class="hljs-selector-tag">node</span>, <span class="hljs-selector-tag">score</span><br /><span class="hljs-selector-tag">RETURN</span> <span class="hljs-selector-tag">node</span><span class="hljs-selector-class">.index</span> <span class="hljs-selector-tag">AS</span> <span class="hljs-selector-tag">index</span>, <span class="hljs-selector-tag">score</span></span></pre><p name="2019" id="2019" class="graf graf--p graf-after--pre">If you run this query, you will get only a single node returned, even though you requested the top <strong class="markup--strong markup--p-strong">3</strong> neighbors to be returned. Why is that so? The vector index only indexes property values, where the value is a list of floats with the specified size. In this example, only one <code class="markup--code markup--p-code">embedding</code>property value had the list of floats type with the selected length 1536.</p><p name="9f45" id="9f45" class="graf graf--p graf-after--p">A node is indexed by the vector index if all the following are true:</p><ul class="postList"><li name="5b80" id="5b80" class="graf graf--li graf-after--p">The node contains the configured label.</li><li name="005d" id="005d" class="graf graf--li graf-after--li">The node contains the configured property key.</li><li name="a01e" id="a01e" class="graf graf--li graf-after--li">The respective property value is of type <code class="markup--code markup--li-code">LIST&lt;FLOAT&gt;</code>.</li><li name="065b" id="065b" class="graf graf--li graf-after--li">The <code class="markup--code markup--li-code"><a href="https://neo4j.com/docs/cypher-manual/current/functions/scalar/#functions-size" data-href="https://neo4j.com/docs/cypher-manual/current/functions/scalar/#functions-size" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">size()</a></code> of the respective value is the same as the configured dimensionality.</li><li name="d3d4" id="d3d4" class="graf graf--li graf-after--li">The value is a valid vector for the configured similarity function.</li></ul><h4 name="1f54" id="1f54" class="graf graf--h4 graf-after--li">Integrating the vector index into the LangChain ecosystem</h4><p name="d5e4" id="d5e4" class="graf graf--p graf-after--h4">Now we will implement a simple custom LangChain class that will use the Neo4j Vector index to retrieve relevant information to generate accurate and up-to-date answers. But first, we have to populate the vector index.</p><figure name="57c8" id="57c8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*2c9ssjs2pJS7L5KWIA0AAw.png" data-width="1062" data-height="646" src="https://cdn-images-1.medium.com/max/800/1*2c9ssjs2pJS7L5KWIA0AAw.png"><figcaption class="imageCaption">Data flow using the Neo4j vector index in RAG applications. Image by the author. Icons from flaticons.</figcaption></figure><p name="cf1c" id="cf1c" class="graf graf--p graf-after--figure">The task will consist of the following steps:</p><ul class="postList"><li name="1aa7" id="1aa7" class="graf graf--li graf-after--p">Retrieve a Wikipedia article</li><li name="6286" id="6286" class="graf graf--li graf-after--li">Chunk the text</li><li name="d00f" id="d00f" class="graf graf--li graf-after--li">Store the text along with its vector representation in Neo4j</li><li name="9953" id="9953" class="graf graf--li graf-after--li">Implement a custom LangChain class to support RAG applications</li></ul><p name="841a" id="841a" class="graf graf--p graf-after--li">In this example, we will fetch only a single Wikipedia article. I have decided to use <a href="https://en.wikipedia.org/wiki/Baldur%27s_Gate_3" data-href="https://en.wikipedia.org/wiki/Baldur%27s_Gate_3" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Baldur’s Gate 3 page</a>.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="c591" id="c591" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">import</span> wikipedia<br />bg3 = wikipedia.page(pageid=<span class="hljs-number">60979422</span>)</span></pre><p name="4293" id="4293" class="graf graf--p graf-after--pre">Next, we need to chunk and embed the text. We will split the text by section using the double newline delimiter and then use OpenAI’s embedding model to represent each section with an appropriate vector.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="e1b1" id="e1b1" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">import</span> os<br /><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> OpenAIEmbeddings<br /><br />os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&quot;API_KEY&quot;</span><br /><br />embeddings = OpenAIEmbeddings()<br /><br />chunks = [{<span class="hljs-string">&#x27;text&#x27;</span>:el, <span class="hljs-string">&#x27;embedding&#x27;</span>: embeddings.embed_query(el)} <span class="hljs-keyword">for</span><br />                  el <span class="hljs-keyword">in</span> bg3.content.split(<span class="hljs-string">&quot;\n\n&quot;</span>) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(el) &gt; <span class="hljs-number">50</span>]</span></pre><p name="9459" id="9459" class="graf graf--p graf-after--pre">Before we move on to the LangChain class, we need to import the text chunks into Neo4j.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="0a5b" id="0a5b" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">graph.query(<span class="hljs-string">&quot;&quot;&quot;<br />UNWIND $data AS row<br />CREATE (c:Chunk {text: row.text})<br />WITH c, row<br />CALL db.create.setVectorProperty(c, &#x27;embedding&#x27;, row.embedding)<br />YIELD node<br />RETURN distinct &#x27;done&#x27;<br />&quot;&quot;&quot;</span>, {<span class="hljs-string">&#x27;data&#x27;</span>: chunks})</span></pre><p name="b4bf" id="b4bf" class="graf graf--p graf-after--pre">One thing you can notice is that I used the <code class="markup--code markup--p-code">db.create.setVectorProperty</code> procedure to store the vectors to Neo4j. This procedure is used to verify that the property value is indeed a list of floats. Additionally, it has the added benefit of reducing the storage space of vector property by approximately 50%. Therefore, it is recommended always to use this procedure to store vectors to Neo4j.</p><p name="1d3c" id="1d3c" class="graf graf--p graf-after--p">Now we can go and implement the custom LangChain class used to retrieve information from Neo4j vector index and use it to generate answers. First, we will define the Cypher statement used to retrieve information.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="90ab" id="90ab" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">vector_search = <span class="hljs-string">&quot;&quot;&quot;<br />WITH $embedding AS e<br />CALL db.index.vector.queryNodes(&#x27;wikipedia&#x27;,$k, e) yield node, score<br />RETURN node.text AS result<br />&quot;&quot;&quot;</span></span></pre><p name="84f6" id="84f6" class="graf graf--p graf-after--pre">As you can see, I have hardcoded the index name. You can make this dynamic by adding appropriate parameters if you wish.</p><p name="6bf5" id="6bf5" class="graf graf--p graf-after--p">The custom LangChain class is implemented pretty straightforward.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="e7f9" id="e7f9" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Neo4jVectorChain</span>(<span class="hljs-title class_ inherited__">Chain</span>):<br />    <span class="hljs-string">&quot;&quot;&quot;Chain for question-answering against a Neo4j vector index.&quot;&quot;&quot;</span><br /><br />    graph: Neo4jGraph = Field(exclude=<span class="hljs-literal">True</span>)<br />    input_key: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;query&quot;</span>  <span class="hljs-comment">#: :meta private:</span><br />    output_key: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;result&quot;</span>  <span class="hljs-comment">#: :meta private:</span><br />    embeddings: OpenAIEmbeddings = OpenAIEmbeddings()<br />    qa_chain: LLMChain = LLMChain(llm=ChatOpenAI(temperature=<span class="hljs-number">0</span>), prompt=CHAT_PROMPT)<br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_call</span>(<span class="hljs-params">self, inputs: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>], run_manager, k=<span class="hljs-number">3</span></span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]:<br />        <span class="hljs-string">&quot;&quot;&quot;Embed a question and do vector search.&quot;&quot;&quot;</span><br />        question = inputs[self.input_key]<br />        <br />        <span class="hljs-comment"># Embed the question</span><br />        embedding = self.embeddings.embed_query(question)<br />        <br />        <span class="hljs-comment"># Retrieve relevant information from the vector index</span><br />        context = self.graph.query(<br />            vector_search, {<span class="hljs-string">&#x27;embedding&#x27;</span>: embedding, <span class="hljs-string">&#x27;k&#x27;</span>: <span class="hljs-number">3</span>})<br />        context = [el[<span class="hljs-string">&#x27;result&#x27;</span>] <span class="hljs-keyword">for</span> el <span class="hljs-keyword">in</span> context]<br />        <br />        <span class="hljs-comment"># Generate the answer</span><br />        result = self.qa_chain(<br />            {<span class="hljs-string">&quot;question&quot;</span>: question, <span class="hljs-string">&quot;context&quot;</span>: context},<br />        )<br />        final_result = result[self.qa_chain.output_key]<br />        <span class="hljs-keyword">return</span> {self.output_key: final_result}</span></pre><p name="fb4c" id="fb4c" class="graf graf--p graf-after--pre">I have omitted some boilerplate code to make it more readable. Essentially, when you can call the Neo4jVectorChain, the following steps are executed:</p><ol class="postList"><li name="52e6" id="52e6" class="graf graf--li graf-after--p">Embed the question using the relevant embedding model</li><li name="d16b" id="d16b" class="graf graf--li graf-after--li">Use the text embedding value to retrieve most similar content from the vector index</li><li name="0079" id="0079" class="graf graf--li graf-after--li">Use the provided context from similar content to generate the answer</li></ol><p name="d32e" id="d32e" class="graf graf--p graf-after--li">We can now test our implementation.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="0a09" id="0a09" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">vector_qa = Neo4jVectorChain(graph=graph, embeddings=embeddings, verbose=<span class="hljs-literal">True</span>)<br />vector_qa.run(<span class="hljs-string">&quot;What is the gameplay of Baldur&#x27;s Gate 3 like?&quot;</span>)</span></pre><p name="4028" id="4028" class="graf graf--p graf-after--pre"><em class="markup--em markup--p-em">Response</em></p><figure name="4c22" id="4c22" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*U05wILUMLsnWE1s-i9ELFA.png" data-width="1063" data-height="276" src="https://cdn-images-1.medium.com/max/800/1*U05wILUMLsnWE1s-i9ELFA.png"><figcaption class="imageCaption">Generated response. Image by the author.</figcaption></figure><p name="172b" id="172b" class="graf graf--p graf-after--figure">By using the <code class="markup--code markup--p-code">verbose</code> option, you can also evaluate the retrieved context from the vector index that was used to generate the answer.</p><h4 name="e2b7" id="e2b7" class="graf graf--h4 graf-after--p">Summary</h4><p name="7090" id="7090" class="graf graf--p graf-after--h4">Leveraging Neo4j’s new vector indexing capabilities, you can create a unified data source that powers Retrieval Augmented Generation applications effectively. This allows you to not only implement “Chat with your PDF or documentation” solutions but also to conduct real-time analytics, all from a single, robust data source. This multi-purpose utility can streamline your operations and enhances data synergy, making Neo4j a great solution for managing both structured and unstructured data.</p><p name="70c7" id="70c7" class="graf graf--p graf-after--p graf--trailing">As always, the code is available on <a href="https://github.com/tomasonjo/blogs/blob/master/llm/Neo4j_vector_index_%26_Langchain.ipynb" data-href="https://github.com/tomasonjo/blogs/blob/master/llm/Neo4j_vector_index_%26_Langchain.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GitHub</a>.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@bratanic-tomaz" class="p-author h-card">Tomaz Bratanic</a> on <a href="https://medium.com/p/8179ad7ff451"><time class="dt-published" datetime="2023-08-23T23:46:01.909Z">August 23, 2023</time></a>.</p><p><a href="https://medium.com/@bratanic-tomaz/efficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on November 5, 2023.</p></footer></article></body></html>