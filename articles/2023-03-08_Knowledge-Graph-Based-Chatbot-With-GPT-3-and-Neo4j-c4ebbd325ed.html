<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Knowledge Graph-Based Chatbot With GPT-3 and Neo4j</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Knowledge Graph-Based Chatbot With GPT-3 and Neo4j</h1>
</header>
<section data-field="subtitle" class="p-summary">
Learn how to develop a chatbot that provides answers based on data stored in a knowledge graph
</section>
<section data-field="body" class="e-content">
<section name="2b46" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="5a00" id="5a00" class="graf graf--h3 graf--leading graf--title">Knowledge Graph-Based Chatbot With GPT-3 and Neo4j</h3><h4 name="682a" id="682a" class="graf graf--h4 graf-after--h3 graf--subtitle">Learn how to develop a chatbot that provides answers based on data stored in a knowledge graph.</h4><p name="5f72" id="5f72" class="graf graf--p graf-after--h4">ChatGPT has changed how I, and probably most of you, look at AI and chatbots. We can use chatbots to help us find information, construct creative works, and more.</p><p name="9a66" id="9a66" class="graf graf--p graf-after--p">However, one problem with ChatGPT and similar chatbots is that they can hallucinate and return great-sounding — yet wildly inaccurate — results. The problem is that these large language models (LLM) are inherently black boxes, so it is hard to fix and retrain models to reduce hallucinations. Consequently, it might not be a good idea to depend on answers from ChatGPT if mission-critical tasks or lives are at stake.</p><p name="334d" id="334d" class="graf graf--p graf-after--p">On the other hand, there is tremendous value in having the ability to interact with chatbots and use them as an interface for various applications.</p><p name="84a9" id="84a9" class="graf graf--p graf-after--p">So I wanted to learn more about chatbots, and luckily <a href="https://medium.com/u/ff9d63e09a67" data-href="https://medium.com/u/ff9d63e09a67" data-anchor-type="2" data-user-id="ff9d63e09a67" data-action-value="ff9d63e09a67" data-action="show-user-card" data-action-type="hover" class="markup--user markup--p-user" target="_blank">Sixing Huang</a> gave me a crash course on different ways of implementing a chatbot. I was especially intrigued by the knowledge graph-based approach to chatbots, where the chatbot returns answers based on information and facts stored in the knowledge graph.</p><p name="26b5" id="26b5" class="graf graf--p graf-after--p">Using a knowledge graph as a storage object for answers gives you explicit and complete control over the answers provided by the chatbot and allows you to avoid hallucinations. Additionally, Sixing has already written about and shared the code to <a href="https://towardsdatascience.com/gpt-3-for-doctor-ai-1396d1cd6fa5" data-href="https://towardsdatascience.com/gpt-3-for-doctor-ai-1396d1cd6fa5" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">implement a knowledge graph-based chatbot</a>, which meant I could borrow some existing ideas and wouldn’t have to start from scratch.</p><p name="6e13" id="6e13" class="graf graf--p graf-after--p">My idea was to develop a chatbot that could be used to explore, analyze, and understand news articles.</p><figure name="5029" id="5029" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*hOjF9ozNte29JVSARHUyvA.png" data-width="478" data-height="215" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*hOjF9ozNte29JVSARHUyvA.png"><figcaption class="imageCaption">Chatbot interface. Image by the author.</figcaption></figure><p name="9b83" id="9b83" class="graf graf--p graf-after--figure">But first, I had to construct a knowledge graph based on news articles. Luckily, I have used and written about the information extraction pipeline numerous times, so I didn’t have to lose time doing that. Next, it was time to implement my first chatbot. It turned out that creating a knowledge graph-based chatbot is as easy as a walk in the park thanks to GPT-3. I constructed the following chatbot architecture.</p><figure name="263e" id="263e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qC53DXQRyTYJVyKeHZ1rbA.png" data-width="585" data-height="249" src="https://cdn-images-1.medium.com/max/800/1*qC53DXQRyTYJVyKeHZ1rbA.png"><figcaption class="imageCaption">Knowledge graph based chatbot architecture. Image by the author.</figcaption></figure><p name="d265" id="d265" class="graf graf--p graf-after--figure">The user talks to a Chatbot on a simple <a href="https://streamlit.io/" data-href="https://streamlit.io/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Streamlit application</a>. When the user inputs their question, the question gets sent to the <a href="https://openai.com/api/" data-href="https://openai.com/api/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">OpenAI GPT-3 endpoint</a> with a request to turn it into a Cypher statement. The OpenAI endpoint returns a Cypher statement, which is then used to retrieve the information from the knowledge graph stored in <a href="https://neo4j.com/" data-href="https://neo4j.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Neo4j</a>. The retrieved data from the knowledge graph is then used to construct the answer to the user’s question. Additionally, I have added the option to summarize articles using the GPT-3 endpoint, which will be demonstrated later.</p><p name="583a" id="583a" class="graf graf--p graf-after--p"><em class="markup--em markup--p-em">All the code is available on </em><a href="https://github.com/tomasonjo/NeoGPT-Explorer" data-href="https://github.com/tomasonjo/NeoGPT-Explorer" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">GitHub</em></a><em class="markup--em markup--p-em">.</em></p><h4 name="9825" id="9825" class="graf graf--h4 graf-after--p">Constructing a knowledge graph</h4><p name="f2c1" id="f2c1" class="graf graf--p graf-after--h4">In order to be able to retrieve information from the knowledge graph, we first have to populate it. As mentioned, the idea is to construct a knowledge graph of news articles. Therefore, we need to find a source of quality and accurate news articles. For the purpose of this demonstration, I have used the latest 1000 articles <a href="https://www.kaggle.com/datasets/adityakharosekar2/guardian-news-articles" data-href="https://www.kaggle.com/datasets/adityakharosekar2/guardian-news-articles" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">available as a Kaggle repository</a>. The articles are available under the CC BY-NC 4.0 license.</p><p name="a46c" id="a46c" class="graf graf--p graf-after--p">We won’t be delving into details about the information extraction pipeline, as I have already written about this subject many times.</p><ul class="postList"><li name="6526" id="6526" class="graf graf--li graf-after--p"><a href="https://towardsdatascience.com/extract-knowledge-from-text-end-to-end-information-extraction-pipeline-with-spacy-and-neo4j-502b2b1e0754" data-href="https://towardsdatascience.com/extract-knowledge-from-text-end-to-end-information-extraction-pipeline-with-spacy-and-neo4j-502b2b1e0754" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Information extraction pipeline with SpaCy and REBEL</a></li><li name="dba6" id="dba6" class="graf graf--li graf-after--li"><a href="https://towardsdatascience.com/construct-a-biomedical-knowledge-graph-with-nlp-1f25eddc54a0" data-href="https://towardsdatascience.com/construct-a-biomedical-knowledge-graph-with-nlp-1f25eddc54a0" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Biomedical information extraction pipeline</a></li><li name="49ea" id="49ea" class="graf graf--li graf-after--li"><a href="https://medium.com/neo4j/monitoring-the-cryptocurrency-space-with-nlp-and-knowledge-graphs-92a1cfaebd1a" data-href="https://medium.com/neo4j/monitoring-the-cryptocurrency-space-with-nlp-and-knowledge-graphs-92a1cfaebd1a" class="markup--anchor markup--li-anchor" target="_blank">Extracting information from news</a></li></ul><p name="38fa" id="38fa" class="graf graf--p graf-after--li">For the most part, the idea behind the information extraction pipeline is to extract structured information about mentioned entities and relationships from unstructured text.</p><figure name="9644" id="9644" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*bhRPZE9EX7ayvkse_Oy3aw.png" data-width="565" data-height="445" src="https://cdn-images-1.medium.com/max/800/1*bhRPZE9EX7ayvkse_Oy3aw.png"><figcaption class="imageCaption">Information extraction pipeline. Image by the author.</figcaption></figure><p name="77f8" id="77f8" class="graf graf--p graf-after--figure">In this example, the information extraction pipeline would identify entities <strong class="markup--strong markup--p-strong">John Snow</strong> and <strong class="markup--strong markup--p-strong">NASA</strong> in the text. Additionally, most named entity recognition models can infer the entity type, meaning that it deduces whether the mentioned entity is a person, organization, or other.</p><p name="bab6" id="bab6" class="graf graf--p graf-after--p">In the next step, a relationship extraction model is used to detect any structured relationships between entities. The text in the above image clearly signifies the working relationship between <strong class="markup--strong markup--p-strong">John Snow</strong> and <strong class="markup--strong markup--p-strong">NASA</strong>, which can be represented as an <strong class="markup--strong markup--p-strong">EMPLOYEE</strong> relationship.</p><p name="9886" id="9886" class="graf graf--p graf-after--p">Interestingly, we could use GPT-3 to extract structured information from text. A project <a href="https://github.com/varunshenoy/GraphGPT" data-href="https://github.com/varunshenoy/GraphGPT" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GraphGPT</a> provides a simple prompt that can be used to generate structured data based on an input text.</p><figure name="abb1" id="abb1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*WInSGAaMPEsNOrwReJYC0g.png" data-width="760" data-height="367" src="https://cdn-images-1.medium.com/max/800/1*WInSGAaMPEsNOrwReJYC0g.png"><figcaption class="imageCaption">Using GraphGPT prompt to extract structured information from text. Image by the author.</figcaption></figure><p name="8f06" id="8f06" class="graf graf--p graf-after--figure">GPT-3 does a decent job of extracting relevant information from the text. It also knows that <strong class="markup--strong markup--p-strong">Boris</strong> in the second sentence references <strong class="markup--strong markup--p-strong">Boris Johnson</strong>,<strong class="markup--strong markup--p-strong"> </strong>which is excellent. However, it does not recognize that <strong class="markup--strong markup--p-strong">the UK</strong> and <strong class="markup--strong markup--p-strong">the United Kingdom</strong> reference the same real-world entity. Entity disambiguation is a vital part of any information extraction pipeline. One approach could be to use an entity-linking strategy to map entities to a target knowledge base. Frequently, Wikipedia is used as a target knowledge base.</p><figure name="cb84" id="cb84" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*tQtxOo6qVIclwATZ8OPTOg.png" data-width="744" data-height="291" src="https://cdn-images-1.medium.com/max/800/1*tQtxOo6qVIclwATZ8OPTOg.png"><figcaption class="imageCaption">Asking GPT-3 to link extracted entities to Wikidata. Image by the author.</figcaption></figure><p name="312b" id="312b" class="graf graf--p graf-after--figure">It is fantastic what we can achieve with a simple prompt using GPT-3 endpoint. Immediately, you can notice that both <strong class="markup--strong markup--p-strong">UK</strong> and <strong class="markup--strong markup--p-strong">United Kindom</strong> map to the same <a href="https://www.wikidata.org/wiki/Q145" data-href="https://www.wikidata.org/wiki/Q145" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Q145</a> id, which can be used for entity disambiguation. On the other hand, Boris Johnson is linked to <a href="https://www.wikidata.org/wiki/Q1446" data-href="https://www.wikidata.org/wiki/Q1446" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Q1446</a> in both instances. All that would be great, however, the id <a href="https://www.wikidata.org/wiki/Q1446" data-href="https://www.wikidata.org/wiki/Q1446" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Q1446</a> refers to a roman emperor <strong class="markup--strong markup--p-strong">Caracalla</strong>.</p><figure name="6ab3" id="6ab3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qPExDLrwFvybRi2Mv7X6Sw.png" data-width="939" data-height="385" src="https://cdn-images-1.medium.com/max/800/1*qPExDLrwFvybRi2Mv7X6Sw.png"><figcaption class="imageCaption">Wikidata entry for ID Q1446. Image by the author.</figcaption></figure><p name="888e" id="888e" class="graf graf--p graf-after--figure">While GPT-3 is excellent at following prompts, it tends to hallucinate external information like WikiData ids. While we might provide a good prompt for entity disambiguation in a single paragraph, it is hard to construct a good way to disambiguate entities between various texts without entity linking.</p><p name="5947" id="5947" class="graf graf--p graf-after--p">We could develop our information extraction pipeline that deals with relation extraction and entity linking. I implemented<a href="https://towardsdatascience.com/from-text-to-knowledge-the-information-extraction-pipeline-b65e7e30273e" data-href="https://towardsdatascience.com/from-text-to-knowledge-the-information-extraction-pipeline-b65e7e30273e" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> such a pipeline two years ago</a>. However, since two years is a lot in the field of NLP, we might find a solution that provides better accuracy.</p><p name="aec9" id="aec9" class="graf graf--p graf-after--p">To avoid developing a custom information pipeline, we will use a <a href="https://www.diffbot.com/products/natural-language/" data-href="https://www.diffbot.com/products/natural-language/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Diffbot NLP endpoint</a>. The Diffbot NLP endpoint extracts relationships and provides entity linking out of the box. Additionally, it offers both paragraph and entity-level sentiments, which significantly expand the set of questions we can ask our chatbot, as we can ask it about positive or negative news regarding particular people or entities.</p><p name="5627" id="5627" class="graf graf--p graf-after--p">The code to run the information extraction pipeline using the Diffbot endpoint is available as <a href="https://github.com/tomasonjo/NeoGPT-Explorer/blob/main/notebooks/Preprocess.ipynb" data-href="https://github.com/tomasonjo/NeoGPT-Explorer/blob/main/notebooks/Preprocess.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">a Jupyter notebook</a>. For this demonstration, you don’t need to run it, as I have stored the output of the information extraction pipeline in the project’s data folder. However, if you want to test it on other datasets and evaluate how it performs, do give it a try.</p><p name="edba" id="edba" class="graf graf--p graf-after--p">Now that the new articles have been processed, we can import the output of the information extraction pipeline into a graph database. In this example, we will be using <a href="https://neo4j.com/" data-href="https://neo4j.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Neo4j</a>. The <a href="https://github.com/tomasonjo/NeoGPT-Explorer" data-href="https://github.com/tomasonjo/NeoGPT-Explorer" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GitHub repository</a> is set up to run as two docker services, one for Neo4j and the other for the Streamlit application, so you don’t have to install Neo4j on your own.</p><p name="2c6d" id="2c6d" class="graf graf--p graf-after--p">You can either run the <code class="markup--code markup--p-code">seed_database.sh</code> script or execute the <a href="https://github.com/tomasonjo/NeoGPT-Explorer/blob/main/notebooks/Import.ipynb" data-href="https://github.com/tomasonjo/NeoGPT-Explorer/blob/main/notebooks/Import.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Import notebook</a> to populate the graph database with news articles. The graph schema of the populated knowledge graph about the news is the following:</p><figure name="2408" id="2408" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*eRhZdrHiPlqOmYufkI_HuQ.png" data-width="505" data-height="381" src="https://cdn-images-1.medium.com/max/800/1*eRhZdrHiPlqOmYufkI_HuQ.png"><figcaption class="imageCaption">Schema of the populated knowledge graph. Image by the author.</figcaption></figure><p name="b4a7" id="b4a7" class="graf graf--p graf-after--figure">The knowledge graph contains <strong class="markup--strong markup--p-strong">Article</strong> nodes containing information about the article’s web title, body content or text, and sentiment. In addition, the articles can mention one or multiple <strong class="markup--strong markup--p-strong">Entity</strong> nodes. The Entity nodes contain the URL property, which is the output of the entity-linking process, along with their id and type.</p><p name="5f78" id="5f78" class="graf graf--p graf-after--p">Interestingly, the relationships between entities are not represented as connections in a graph but rather as separate Relationship nodes. The idea behind this graph modeling decision is that we want to track the text where the extracted relationships originate from. As we know, no NLP pipeline is perfect. Therefore it is essential to have the ability to verify if a relationship is accurately extracted by manually examining the originating text. In a labeled property graph database like Neo4j, we cannot have a connection pointing to another connection. Consequently, we model the extracted relationships between entities as an intermediate node.</p><h4 name="f29d" id="f29d" class="graf graf--h4 graf-after--p">Using a GPT-3 model to generate Cypher statements</h4><p name="6904" id="6904" class="graf graf--p graf-after--h4">We have already learned that GPT-3 does a great job of following orders given in a prompt. Additionally, <a href="https://medium.com/u/ff9d63e09a67" data-href="https://medium.com/u/ff9d63e09a67" class="markup--anchor markup--p-anchor" target="_blank">Sixing Huang</a> has already written about how easy it is to <a href="https://towardsdatascience.com/gpt-3-for-doctor-ai-1396d1cd6fa5" data-href="https://towardsdatascience.com/gpt-3-for-doctor-ai-1396d1cd6fa5" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">train the GPT-3 model to generate Cypher statements</a>. The idea is to give the model a few examples and then let it generate a Cypher statement given the new user input. Specifically, I have prepared the following Cypher examples to train the GPT-3 model.</p><figure name="041f" id="041f" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/f5cf203397a9617e180730156a8dae62.js"></script></figure><p name="c25f" id="c25f" class="graf graf--p graf-after--figure">Unfortunately, the GPT-3 endpoint has no concept of context, so we need to send the training examples along with every user input. I wonder what the ChatGPT API endpoint will look like, as ChatGPT has a concept of the context of a dialogue and how it will affect end-user applications.</p><figure name="da49" id="da49" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*MBajRwgMG67YTZ9oP1d1Og.png" data-width="711" data-height="331" src="https://cdn-images-1.medium.com/max/800/1*MBajRwgMG67YTZ9oP1d1Og.png"><figcaption class="imageCaption">GPT-3 request to generate Cypher statements. Image by the author.</figcaption></figure><p name="55b9" id="55b9" class="graf graf--p graf-after--figure">As shown in this image, every request to the GPT-3 endpoint starts with training examples. Interestingly, we don’t have to tell the model it should generate Cypher statements or anything — we just provide training examples along with a user prompt, and the model generates Cypher statements.</p><h4 name="392b" id="392b" class="graf graf--h4 graf-after--p">Chatbot implementation</h4><p name="50ad" id="50ad" class="graf graf--p graf-after--h4">Now that we have prepared all the pieces of the puzzle, we can combine them in a chatbot application. I have used a Streamlit application — specifically <a href="https://github.com/AI-Yash/st-chat" data-href="https://github.com/AI-Yash/st-chat" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">streamlit-chat</a> — to implement the user interface for the chatbot. I like the Streamlit application as it keeps things simple, and I can use Python to develop the user interface while avoiding any meddling with CSS.</p><p name="4b22" id="4b22" class="graf graf--p graf-after--p">The application uses the following Python code to generate the chatbot responses.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="afae" id="afae" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Make a request to GPT-3 endpoint</span><br />completions = openai.Completion.create(<br />      engine=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br />      <span class="hljs-comment"># Construct the prompt using the training examples</span><br />      <span class="hljs-comment"># combined with user input</span><br />      prompt=examples + <span class="hljs-string">&quot;\n#&quot;</span> + prompt,<br />      max_tokens=<span class="hljs-number">1000</span>,<br />      n=<span class="hljs-number">1</span>,<br />      stop=<span class="hljs-literal">None</span>,<br />      temperature=<span class="hljs-number">0.5</span>,<br />  )<br />  <span class="hljs-comment"># Extract Cypher query from GPT-3 response</span><br />  cypher_query = completions.choices[<span class="hljs-number">0</span>].text<br />  <span class="hljs-comment"># Use the Cypher query to read the knowledge graph</span><br />  message = read_query(cypher_query)<br />  <span class="hljs-keyword">return</span> message, cypher_query</span></pre><p name="7b57" id="7b57" class="graf graf--p graf-after--pre">As mentioned, all the code is available on <a href="https://github.com/tomasonjo/NeoGPT-Explorer" data-href="https://github.com/tomasonjo/NeoGPT-Explorer" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GitHub</a> if you are interested in more details. The repository also includes instructions to run the chatbot application.</p><p name="1cef" id="1cef" class="graf graf--p graf-after--p">Let’s now try the chatbot and see how well it behaves. We can start by using an example from the training set of questions. The question is: “<strong class="markup--strong markup--p-strong">What are the latest positive news?”</strong></p><figure name="12c8" id="12c8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jv75WO9tcYAy93gjtLXG9g.png" data-width="774" data-height="465" src="https://cdn-images-1.medium.com/max/800/1*jv75WO9tcYAy93gjtLXG9g.png"><figcaption class="imageCaption">Image by the author.</figcaption></figure><p name="d593" id="d593" class="graf graf--p graf-after--figure">The generated Cypher query is available on the right side of the chatbot user interface to allow for easy evaluation of generated Cypher statements. The question is in the training set, and therefore, the generated Cypher statement is identical to the example we provided.</p><p name="3c4c" id="3c4c" class="graf graf--p graf-after--p">Next, we can try a variation of a question that is outside the training set. However, similar examples are provided, and GPT-3 needs to combine information from two examples to generate the Cypher statement.</p><figure name="6cee" id="6cee" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*DgORdpFH5YBmVr0jBBCYzg.png" data-width="780" data-height="446" src="https://cdn-images-1.medium.com/max/800/1*DgORdpFH5YBmVr0jBBCYzg.png"><figcaption class="imageCaption">Image by the author.</figcaption></figure><p name="ed19" id="ed19" class="graf graf--p graf-after--figure">Given that we provided only 11 training examples, I am impressed with how well GPT-3 can generalize and construct appropriate Cypher statements. On the other hand, I am quite pleased with how easy it is to drill down the information provided in previous answers. It makes investigative work more fun and more accessible as you can use natural language to explore data instead of having to write Cypher statements.</p><p name="2b11" id="2b11" class="graf graf--p graf-after--p">We can follow up and ask the chatbot about the information we have stored about Emla Fitzsimons in the knowledge graph.</p><figure name="9faa" id="9faa" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*jHKe_NcDnoEQnyNucBjCaA.png" data-width="816" data-height="540" src="https://cdn-images-1.medium.com/max/800/1*jHKe_NcDnoEQnyNucBjCaA.png"><figcaption class="imageCaption">Image by the author.</figcaption></figure><p name="8ba3" id="8ba3" class="graf graf--p graf-after--figure">The chatbot provides information about the extracted relationships which involve the particular person. In this example, we know that Emla is an employee of the Centre for Longitudinal studies, works with Marcos Vera-Hernandez, and is interested in economics. This information was extracted using the Diffbot NLP endpoint and stored in the knowledge graph.</p><p name="0f06" id="0f06" class="graf graf--p graf-after--p">We can ask the chatbot if there are any more news about Emla.</p><figure name="173c" id="173c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*h0q2b8DL0yOqLR4SqLoSpg.png" data-width="817" data-height="379" src="https://cdn-images-1.medium.com/max/800/1*h0q2b8DL0yOqLR4SqLoSpg.png"><figcaption class="imageCaption">Image by the author.</figcaption></figure><p name="e649" id="e649" class="graf graf--p graf-after--figure">It seems Emla is mentioned only in one article. I thought it would be cool to add an option to summarize news articles using the GPT-3 endpoint. As GPT-3 model follows orders quite well, you only need to ask it to summarize text, which does the job.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="f273" id="f273" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Make a request to GPT-3 endpoint</span><br />completions = openai.Completion.create(<br />    engine=<span class="hljs-string">&quot;text-davinci-003&quot;</span>,<br />    <span class="hljs-comment"># Prefix the prompt with a request to provide a summary</span><br />    prompt=<span class="hljs-string">&quot;Summarize the following article: \n&quot;</span> + prompt,<br />    max_tokens=<span class="hljs-number">256</span>,<br />    n=<span class="hljs-number">1</span>,<br />    stop=<span class="hljs-literal">None</span>,<br />    temperature=<span class="hljs-number">0.5</span>,<br />)<br />message = completions.choices[<span class="hljs-number">0</span>].text<br /><span class="hljs-keyword">return</span> message, <span class="hljs-literal">None</span></span></pre><p name="b2a6" id="b2a6" class="graf graf--p graf-after--pre">I have added a simple exception in the code. If the user input contains <strong class="markup--strong markup--p-strong">summar</strong>, then we assume the task is to provide a summary of the given article.</p><figure name="2be6" id="2be6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Q4rlBHHuFTk8kzSBG_WX_w.png" data-width="861" data-height="521" src="https://cdn-images-1.medium.com/max/800/1*Q4rlBHHuFTk8kzSBG_WX_w.png"><figcaption class="imageCaption">Image by the author.</figcaption></figure><p name="32b7" id="32b7" class="graf graf--p graf-after--figure">Since the knowledge graph contains both article and entity-level sentiment, we can search for any entities with positive or negative sentiment. For example, we can search for organizations that have been mentioned positively in the news.</p><figure name="5334" id="5334" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*iAbaGfZNtpZnws-xDqmuMw.png" data-width="814" data-height="428" src="https://cdn-images-1.medium.com/max/800/1*iAbaGfZNtpZnws-xDqmuMw.png"><figcaption class="imageCaption">Image by the author.</figcaption></figure><p name="018f" id="018f" class="graf graf--p graf-after--figure">And similar to before, we can ask the chatbot follow-up questions and drill down on the information we are interested in.</p><figure name="a9f6" id="a9f6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1WEMGuBAEY9PjgkJqJHreQ.png" data-width="787" data-height="387" src="https://cdn-images-1.medium.com/max/800/1*1WEMGuBAEY9PjgkJqJHreQ.png"><figcaption class="imageCaption">Image by the author.</figcaption></figure><h4 name="736e" id="736e" class="graf graf--h4 graf-after--figure">Summary</h4><p name="fc4b" id="fc4b" class="graf graf--p graf-after--h4">I wanted to create a project that uses natural language to explore and analyze knowledge graphs for a long time. However, the barrier to entry was too high for me as I am not a machine learning expert, and developing and training a custom model that generates Cypher statements based on user inputs was too big of a task for me.</p><p name="3cde" id="3cde" class="graf graf--p graf-after--p">And frankly, until I joined the ChatGPT hype, I wasn’t genuinely aware of how incredible the underlying technology is and how well it works. For example, we only provided 10 training examples, and the chatbot behaves like it has worked with the given graph schema for the past five years.</p><p name="8fb7" id="8fb7" class="graf graf--p graf-after--p">Hopefully, this article will encourage you to implement your own chatbots and use them to make knowledge graphs and other technologies more accessible!</p><p name="499f" id="499f" class="graf graf--p graf-after--p">To learn more about this topic, join me at NODES 2023, a free online global conference about graph technologies. The CFP is open now until June 30. <a href="https://dev.neo4j.com/nodes23" data-href="https://dev.neo4j.com/nodes23" class="markup--anchor markup--p-anchor" rel="noopener noreferrer noopener" target="_blank">https://dev.neo4j.com/nodes23</a></p><p name="c821" id="c821" class="graf graf--p graf-after--p graf--trailing"><em class="markup--em markup--p-em">The code is available as a </em><a href="https://github.com/tomasonjo/NeoGPT-Explorer" data-href="https://github.com/tomasonjo/NeoGPT-Explorer" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">GitHub repository</em></a><em class="markup--em markup--p-em">.</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@bratanic-tomaz" class="p-author h-card">Tomaz Bratanic</a> on <a href="https://medium.com/p/c4ebbd325ed"><time class="dt-published" datetime="2023-03-08T21:20:58.833Z">March 8, 2023</time></a>.</p><p><a href="https://medium.com/@bratanic-tomaz/knowledge-graph-based-chatbot-with-gpt-3-and-neo4j-c4ebbd325ed" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on November 5, 2023.</p></footer></article></body></html>