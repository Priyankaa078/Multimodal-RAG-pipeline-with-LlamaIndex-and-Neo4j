<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Stay in touch with the latest medical research by utilizing Spark NLP and biomedical knowledge…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Stay in touch with the latest medical research by utilizing Spark NLP and biomedical knowledge…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Construct a biomedical knowledge graph by utilizing NLP techniques to extract relationships from biomedical articles
</section>
<section data-field="body" class="e-content">
<section name="62c6" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="3aa6" id="3aa6" class="graf graf--h3 graf--leading graf--title">Stay in touch with the latest medical research by utilizing Spark NLP and biomedical knowledge graphs</h3><h4 name="80b4" id="80b4" class="graf graf--h4 graf-after--h3 graf--subtitle">Construct a biomedical knowledge graph by utilizing NLP techniques to extract relationships from biomedical articles</h4><p name="f6c2" id="f6c2" class="graf graf--p graf-after--h4">The biomedical domain is a prime example of finding connections and relationships between various entities like genes, drugs, diseases, and more. It is virtually impossible for any doctor to keep in touch with all the latest published research. For example, I queried <a href="https://www.ncbi.nlm.nih.gov/pmc/" data-href="https://www.ncbi.nlm.nih.gov/pmc/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">PubMed Central</a> and found 100 thousand articles published in 2022 when writing this article (10th March). This means that there are more than a thousand articles published every day. Even a big team of doctors would have a problem reading them and extracting valuable insights.</p><p name="8997" id="8997" class="graf graf--p graf-after--p">In order to stay in touch with all the latest biomedical research, we can utilize various NLP techniques. For example, I have already written about constructing a biomedical knowledge graph in my previous blog post. However, the focus was more on named entity recognition. Since then, I’ve found biomedical relation extraction models that we will take a look at in this post.</p><p name="932b" id="932b" class="graf graf--p graf-after--p">We will quickly recap the aim of relation extraction models. For example, let’s say you are analyzing the following sentence:</p><pre name="83e9" id="83e9" class="graf graf--pre graf-after--p">Been taking Lipitor for 15 years , have experienced severe fatigue a lot!</pre><p name="abed" id="abed" class="graf graf--p graf-after--pre">The first step is identifying all the biomedical entities present in the sentence. In this case, we can recognize <strong class="markup--strong markup--p-strong">Lipitor</strong> and <strong class="markup--strong markup--p-strong">severe fatigue</strong>. The relation extraction models are typically very custom and domain-specific. For example, say that we have trained the model to identify adverse drug effects. The adverse drug effect is a relation between a drug and the unintended condition or consequence of a drug. In this case, we could say that Lipitor causes undesired severe fatigue. If you are anything like me, you will think of a graph to store and represent a relationship between two entities.</p><figure name="225e" id="225e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*j_c6lQTjoKbnCEtXcw0P8g.png" data-width="765" data-height="417" src="https://cdn-images-1.medium.com/max/800/1*j_c6lQTjoKbnCEtXcw0P8g.png"><figcaption class="imageCaption">Graph representation of an adverse drug relation. Image by the author</figcaption></figure><p name="0ee2" id="0ee2" class="graf graf--p graf-after--figure">Since graph databases are designed to store entities and their relations, it makes sense to use them to store highly inter-connected data that we extract by utilizing a relation extraction NLP model.</p><h4 name="0147" id="0147" class="graf graf--h4 graf-after--p">Agenda</h4><p name="9015" id="9015" class="graf graf--p graf-after--h4">In this post, we will start by downloading biomedical articles from PubMed. The PubMed provides an API to retrieve data as well as a <a href="https://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/" data-href="https://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">FTP site</a>, where daily updates are available. The FTP site doesn’t have a clear license stated, but it describes the <a href="https://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/README.txt" data-href="https://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/README.txt" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">terms and conditions of using the data</a>:</p><pre name="73c4" id="73c4" class="graf graf--pre graf-after--p">NLM freely provides PubMed data. Please note some abstracts may be protected by copyright.<br>  <br>General Terms and Conditions:<br>-Users of the data agree to: <br>--acknowledge NLM as the source of the data in a clear and conspicuous manner,<br>--properly use registration and/or trademark symbols when referring to NLM products, and<br>--not indicate or imply that NLM has endorsed its products/services/applications.</pre><p name="3151" id="3151" class="graf graf--p graf-after--pre">Since the data will be used for a simple demonstration of an NLP pipeline only, we’re all set.</p><p name="a6a5" id="a6a5" class="graf graf--p graf-after--p">Next, we will run the data through an NLP pipeline to extract relationships between biomedical entities. There are many open-source named entity recognition models out there, but unfortunately, I haven’t come across any biomedical relation extraction models that don’t require manual training. Since the goal of this post is not to teach you how to train a biomedical relation extraction model but rather how to apply it to solve real-world problems, we will be using the <a href="https://www.johnsnowlabs.com/" data-href="https://www.johnsnowlabs.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">John Snow Labs</a> Healthcare models. John Snow Labs offer free models for recognizing entities and extracting relations from news-like text. However, the biomedical models are not open-source. Luckily for us, they offer a free 30-day trial period for healthcare models. To follow along with the examples in this post, you will need to start the free trial and obtain the license keys.</p><p name="63d1" id="63d1" class="graf graf--p graf-after--p">In the last part of this post, we will store the extracted relations in Neo4j, a native graph database designed to store and analyze highly interconnected data. I will also explain some considerations regarding the different graph models we can use to represent the data.</p><h4 name="eb67" id="eb67" class="graf graf--h4 graf-after--p">Steps</h4><ul class="postList"><li name="e988" id="e988" class="graf graf--li graf-after--h4">Download and parse daily update of articles from the PubMed FTP site</li><li name="c3fb" id="c3fb" class="graf graf--li graf-after--li">Store articles in Neo4j</li><li name="82f3" id="82f3" class="graf graf--li graf-after--li">Use John Snow Labs models to extract relations from text</li><li name="f2c7" id="f2c7" class="graf graf--li graf-after--li">Store and analyze relations in Neo4j</li></ul><p name="c123" id="c123" class="graf graf--p graf-after--li">As always, all the code is available as a <a href="https://github.com/tomasonjo/blogs/blob/master/pubmed/Pubmed%20NLP.ipynb" data-href="https://github.com/tomasonjo/blogs/blob/master/pubmed/Pubmed%20NLP.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Google Colab notebook</a>.</p><h4 name="0679" id="0679" class="graf graf--h4 graf-after--p">Download daily update from the PubMed FTP site</h4><p name="74d4" id="74d4" class="graf graf--p graf-after--h4">As mentioned, the PubMed daily updates are available on their <a href="https://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/" data-href="https://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">FTP site</a>. The data is available in XML format. The files have an incremental ID. I’ve first tried to calculate the incremental file id for a specific date programmatically. However, it’s not straightforward, and I didn’t want to waste my time figuring it out, so you will have to copy the desired file location in the code manually.</p><figure name="159c" id="159c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/9f9e12ca81e563af1756932255c79675.js"></script></figure><p name="57d2" id="57d2" class="graf graf--p graf-after--figure">My gut instinct was that it would be easier to convert the XML to a dictionary and process that. However, if I had to do it again, I would probably use XML search functions as I had to include several exceptions to extract required data from the dictionary format correctly.</p><p name="8657" id="8657" class="graf graf--p graf-after--p">The code to parse the dictionary is 70 lines long and not that interesting, so I will skip it here. However, the <a href="https://github.com/tomasonjo/blogs/blob/master/pubmed/Pubmed%20NLP.ipynb" data-href="https://github.com/tomasonjo/blogs/blob/master/pubmed/Pubmed%20NLP.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Colab notebook</a> obviously contains all the code.</p><h4 name="a120" id="a120" class="graf graf--h4 graf-after--p">Store articles in Neo4j</h4><p name="e17d" id="e17d" class="graf graf--p graf-after--h4">Before moving onto the NLP extraction pipeline, we will store the articles in Neo4j. The graph model of articles is the following:</p><figure name="2729" id="2729" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Bcj3qv-gcOUUD6ID83RjFg.png" data-width="1134" data-height="751" src="https://cdn-images-1.medium.com/max/800/1*Bcj3qv-gcOUUD6ID83RjFg.png"><figcaption class="imageCaption">Graph model of PubMed articles. Image by the author.</figcaption></figure><p name="3aa4" id="3aa4" class="graf graf--p graf-after--figure">The graph model is quite self-descriptive. In the center of the graph are the articles. We store their PubMed ids, title, country, and dates as properties. Of course, we could refactor the country as a separate node if we wanted to, but here I modeled them as node properties. Each article contains one or more sections of texts. Several types of sections are available, like the abstract, methods, or conclusions. I’ve stored the section type as the relationship property between the article and the section. We also know who authored a particular research paper. PubMed articles in particular also contain the entities mentioned or researched in the paper, which we will store as the Mesh node as the entities are mapped to the Mesh ontology.</p><p name="7654" id="7654" class="graf graf--p graf-after--p"><em class="markup--em markup--p-em">P.s. For most articles, only the abstract is available. You could probably download full-text for most articles through the PubMed API. However, we won’t do that here.</em></p><p name="bac0" id="bac0" class="graf graf--p graf-after--p">Before importing the data, we have to set up our Neo4j environment. If you are using the Colab notebook, I suggest you open a<a href="https://sandbox.neo4j.com/?usecase=blank-sandbox" data-href="https://sandbox.neo4j.com/?usecase=blank-sandbox" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> Blank Project in Neo4j Sandbox</a>. Neo4j Sandbox is a free time-limited cloud instance of Neo4j. Otherwise, if you want a local Neo4j environment, I suggest you download and install the <a href="https://neo4j.com/download/" data-href="https://neo4j.com/download/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Neo4j Desktop application</a>. Make sure you install the APOC library in your local environment.</p><p name="6ad9" id="6ad9" class="graf graf--p graf-after--p">Once you have set up your Neo4j instance, copy the connection details to script.</p><figure name="871b" id="871b" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/0c78600917f0623ca8dc4ad337bd49e5.js"></script></figure><p name="e9db" id="e9db" class="graf graf--p graf-after--figure">A good practice when dealing with Neo4j is to define unique constraints and indexes to optimize the performance of both import and read queries.</p><figure name="37c8" id="37c8" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/8124e06f6df82b3d8f861e44cc55bb10.js"></script></figure><p name="6bdc" id="6bdc" class="graf graf--p graf-after--figure">Now that we are all set, we can go ahead and import articles into Neo4j.</p><figure name="064d" id="064d" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/a52781160be55397a4a0ca4d758b5b25.js"></script></figure><p name="cae5" id="cae5" class="graf graf--p graf-after--figure">The import is split into batches of 1000 articles to avoid dealing with a single huge transaction and potential memory issues. The import Cypher statement is a bit longer, but nothing too complex. If you need help understanding Cypher syntax, I suggest you complete a course or two at <a href="https://neo4j.com/graphacademy/" data-href="https://neo4j.com/graphacademy/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Neo4j’s Graph Academy</a>.</p><p name="4d04" id="4d04" class="graf graf--p graf-after--p">If you open the Neo4j Browser, you should be able to observe the articles stored in the graph.</p><figure name="9f47" id="9f47" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qwKA3Xk6CyNGAdpKfWhMRQ.png" data-width="1420" data-height="893" src="https://cdn-images-1.medium.com/max/800/1*qwKA3Xk6CyNGAdpKfWhMRQ.png"><figcaption class="imageCaption">Example article stored as a graph. Image by the author.</figcaption></figure><p name="31ee" id="31ee" class="graf graf--p graf-after--figure">We can quickly inspect the data before moving on to the NLP pipeline.</p><pre name="5d3a" id="5d3a" class="graf graf--pre graf-after--p">MATCH (a:Article)<br>RETURN count(*) AS count</pre><p name="5078" id="5078" class="graf graf--p graf-after--pre">There are more than 25000 articles in our database. That’s a bit much as new daily articles should be closer to 1000 than 25000. We can compare the revised versus the completed date to understand better why there are so many articles.</p><pre name="25b7" id="25b7" class="graf graf--pre graf-after--p">MATCH (a:Article)<br>RETURN a.pmid AS article_id,<br>       a.completed_date AS completed_date,<br>       a.revised_date AS revised_date<br>ORDER BY completed_date ASC<br>LIMIT 5</pre><p name="bd57" id="bd57" class="graf graf--p graf-after--pre"><em class="markup--em markup--p-em">Results</em></p><figure name="1b21" id="1b21" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/7d637001115da7456bbf5eda95b22072.js"></script></figure><p name="17bd" id="17bd" class="graf graf--p graf-after--figure">I have no idea why articles older than 20 years are being revised, but we get that information from the XML files. Next, we can inspect which mesh entities are most frequently researched as major topics in the articles completed in 2020 or later.</p><pre name="e9f5" id="e9f5" class="graf graf--pre graf-after--p">MATCH (a:Article)-[rel:MENTIONS_MESH]-&gt;(mesh_entity)<br>WHERE a.completed_date.year &gt;= 2020 AND rel.isMajor = &quot;Y&quot;<br>RETURN mesh_entity.text as entity, count(*) AS count<br>ORDER BY count DESC<br>LIMIT 5</pre><p name="1483" id="1483" class="graf graf--p graf-after--pre"><em class="markup--em markup--p-em">Results</em></p><figure name="2697" id="2697" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/a2173338cb447a50e26651849db49535.js"></script></figure><p name="6440" id="6440" class="graf graf--p graf-after--figure">Interestingly, COVID-19 comes out on top even though we imported only a single daily update. Before relation extraction NLP models gained popularity, you could use co-occurrence networks to identify potential links between entities. For example, we can inspect which entities most frequently co-occur with COVID-19.</p><pre name="2178" id="2178" class="graf graf--pre graf-after--p">MATCH (e1:Mesh)&lt;-[:MENTIONS_MESH]-(a:Article)-[:MENTIONS_MESH]-&gt;(e2)<br>WHERE e1.text = &#39;COVID-19&#39;<br>RETURN e1.text AS entity1, e2.text AS entity2, count(*) AS count<br>ORDER BY count DESC<br>LIMIT 5</pre><p name="99fc" id="99fc" class="graf graf--p graf-after--pre"><em class="markup--em markup--p-em">Results</em></p><figure name="f629" id="f629" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/ec911f1f8803d96d23282d88e0a63303.js"></script></figure><p name="228c" id="228c" class="graf graf--p graf-after--figure">Co-occurrence results for COVID-19 make sense, even though they don’t explain much other than it’s related to humans and pandemics and has a strong connection to SARS-CoV-2.</p><h4 name="a626" id="a626" class="graf graf--h4 graf-after--p">Relation Extraction NLP pipeline</h4><p name="a4f1" id="a4f1" class="graf graf--p graf-after--h4">Simple co-occurrence analysis can be a powerful technique to analyse relations between entities, but it ignores a lot of information that is available in the text. For that reason, researches have been investing a lot of effort in building in training relation extraction models.</p><p name="b204" id="b204" class="graf graf--p graf-after--p">If the co-occurrence analysis can detect potential relationships between entities, relation extraction models are trained to determine the type of relations between entities.</p><figure name="74d0" id="74d0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*W-NM3MRgLiasr7lTlj-luw.png" data-width="561" data-height="362" src="https://cdn-images-1.medium.com/max/800/1*W-NM3MRgLiasr7lTlj-luw.png"><figcaption class="imageCaption">Comparison of co-occurrence analysis and relation extraction models. Image by the author.</figcaption></figure><p name="d28a" id="d28a" class="graf graf--p graf-after--figure">As mentioned, the relation extraction models try to predict the type of relationship between two entities. One simple example of why determining the relationship type is important is the following:</p><figure name="f14c" id="f14c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*yh5nql9jV3hLiYwW5j4z7w.png" data-width="1078" data-height="516" src="https://cdn-images-1.medium.com/max/800/1*yh5nql9jV3hLiYwW5j4z7w.png"><figcaption class="imageCaption">Importance of determining relation type. Image by the author.</figcaption></figure><p name="9f3f" id="9f3f" class="graf graf--p graf-after--figure">A drug can co-occur with a particular condition in the text. However, it’s essential to know if the drug is used to treat the disease or causes the condition as an undesired side effect.</p><p name="0d29" id="0d29" class="graf graf--p graf-after--p">Relationship extraction models are mostly very domain-specific and trained to detect only specific types of links. For this example, I have decided to include two John Snow Labs models in the NLP pipeline. One model will detect <a href="https://nlp.johnsnowlabs.com/2021/07/16/re_ade_biobert_en.html" data-href="https://nlp.johnsnowlabs.com/2021/07/16/re_ade_biobert_en.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">adverse drug effects between drugs and conditions</a>, while the other model is used to extract <a href="https://nlp.johnsnowlabs.com/2022/01/05/redl_drugprot_biobert_en.html" data-href="https://nlp.johnsnowlabs.com/2022/01/05/redl_drugprot_biobert_en.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">relations between drugs and proteins</a>.</p><p name="746a" id="746a" class="graf graf--p graf-after--p">John Snow Labs NLP pipeline is built on top of Apache Spark. Without going into details, the input to the NLP pipeline is a Spark DataFrame. Each step in the pipeline takes input data from and stores its output back to the DataFrame. A quick example is:</p><figure name="4ea8" id="4ea8" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/ff3ad9cbc4571716997d9b7b0d209df3.js"></script></figure><p name="0c5b" id="0c5b" class="graf graf--p graf-after--figure">This example pipeline consists of three steps. The first step is the DocumentAssembler that transforms the input text into a document. It will take as an input the <strong class="markup--strong markup--p-strong">text </strong>column of the Spark DataFrame and output its result into the <strong class="markup--strong markup--p-strong">document</strong> column. The next step is to split a document into sentences using the SentenceDetector. Similarly, the SentenceDetector takes as an input the <strong class="markup--strong markup--p-strong">document</strong> column and stores its result under the <strong class="markup--strong markup--p-strong">sentences</strong> column of the DataFrame.</p><p name="1bec" id="1bec" class="graf graf--p graf-after--p">We can add whatever number of steps we want in the pipeline. The only important thing to note is that we need to ensure that each step in the pipeline has valid input and output columns. While the NLP pipeline definition in this example is simple, there are many steps involved, so I will present it with a diagram rather than copying the code.</p><figure name="4e78" id="4e78" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*zjUJrvwCe26Swqbe7weaqg.png" data-width="501" data-height="694" src="https://cdn-images-1.medium.com/max/800/1*zjUJrvwCe26Swqbe7weaqg.png"><figcaption class="imageCaption">Spark NLP relation extraction biomedical pipeline. Image by the author.</figcaption></figure><p name="9f46" id="9f46" class="graf graf--p graf-after--figure">Some of the steps are relevant for both the ADE (Adverse Drug Effect) and REDL (Drugs and Proteins) relations. However, since the models detect relationships between different types of entities, we have to use two NER models to detect both types of entities. Then we can simply feed those entities into relation extraction models. For example, the ADE model will produce only two types of relationships (0,1), where 1 indicates an adverse drug effect. On the other hand, the REDL model is trained to detect nine different types of relations between drugs and proteins (ACTIVATOR, INHIBITOR, AGONIST…).</p><p name="5957" id="5957" class="graf graf--p graf-after--p">Lastly, we need to define the graph model to represent extracted entities. Mostly, it depends if you want the extracted relationships to point to their original text or not.</p><figure name="4962" id="4962" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Hc_rStGhiuMad3DZvkpQUA.png" data-width="651" data-height="312" src="https://cdn-images-1.medium.com/max/800/1*Hc_rStGhiuMad3DZvkpQUA.png"><figcaption class="imageCaption">Graph schema consideration based on linking to original text or not. Image by the author.</figcaption></figure><p name="74da" id="74da" class="graf graf--p graf-after--figure">The model is pretty straightforward if you don’t need the trail to the original text. However, since we know that NLP extraction is not perfect, we usually want to add a link between the extracted relation and the original text. This model allows us to easily validate any relationship by examining the original text. In the right-hand-side example, I’ve intentionally skipped defining the relationship type between entities and relationship nodes. We could either go with a generic relationship type or use the extracted relationship type like CAUSES, INHIBITS, etc. In this example, I choose to use a generic relationship type, so the final graph model is:</p><figure name="2513" id="2513" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*bTGn3jwJgJeCnv3wA6QdGA.png" data-width="481" data-height="251" src="https://cdn-images-1.medium.com/max/800/1*bTGn3jwJgJeCnv3wA6QdGA.png"><figcaption class="imageCaption">Final graph model of extracted relations. Image by the author.</figcaption></figure><p name="5d44" id="5d44" class="graf graf--p graf-after--figure">The only thing left is to execute the code and import extracted biomedical relations into Neo4j.</p><figure name="9cbb" id="9cbb" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/9162febd9bb80ca3cd64ce0dc7f8ef36.js"></script></figure><p name="76e7" id="76e7" class="graf graf--p graf-after--figure">This code processes only 1000 sections, but you can increase the limit if you want. Since we didn’t specify any unique id of the Section nodes, I’ve fetched the text and section internal node ids from Neo4j, which will make the import of relations faster as matching nodes by long text is not the most optimized way. Usually, you can get around this problem by calculating and storing a hash of text like sha1. In Google Colab, it takes about an hour to process 1000 sections.</p><p name="60bd" id="60bd" class="graf graf--p graf-after--p">Now we can examine the results. First, we will look at the relationships with the most mentions.</p><pre name="6be3" id="6be3" class="graf graf--pre graf-after--p">MATCH (start:Entity)-[:RELATIONSHIP]-&gt;(r)-[:RELATIONSHIP]-&gt;(end:Entity)<br>WITH start, end, r,<br>     size((r)&lt;-[:MENTIONS]-()) AS totalMentions<br>ORDER BY totalMentions DESC<br>LIMIT 5<br>RETURN start.name AS startNode, r.type AS rel_type, end.name AS endNode, totalMentions</pre><p name="f8aa" id="f8aa" class="graf graf--p graf-after--pre"><em class="markup--em markup--p-em">Results</em></p><figure name="3815" id="3815" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/tomasonjo/6b58d13c7e72c77454d89f403acb5304.js"></script></figure><p name="c33e" id="c33e" class="graf graf--p graf-after--figure">Since I am not a medical doctor, I won’t comment the results as I have no idea how accurate they are. If we were to ask a medical doctor if a specific relation is valid, we can present them with the original text and let them decide.</p><pre name="cced" id="cced" class="graf graf--pre graf-after--p">MATCH (start:Entity)-[:RELATIONSHIP]-&gt;(r)-[:RELATIONSHIP]-&gt;(end:Entity)<br>WHERE start.name = &#39;cytokines&#39; AND end.name = &#39;chemokines&#39;<br>MATCH (r)&lt;-[:MENTIONS]-(section)&lt;-[:HAS_SECTION]-(article)<br>RETURN section.text AS text, article.pmid AS pmid<br>LIMIT 5</pre><p name="56b7" id="56b7" class="graf graf--p graf-after--pre"><em class="markup--em markup--p-em">Results</em></p><figure name="3975" id="3975" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*dMKckldtvOq6QsJKiM1SVg.png" data-width="1687" data-height="473" src="https://cdn-images-1.medium.com/max/800/1*dMKckldtvOq6QsJKiM1SVg.png"><figcaption class="imageCaption">Original text for the particular relation. Image by the author.</figcaption></figure><p name="0d72" id="0d72" class="graf graf--p graf-after--figure">What might also be interesting is to search for indirect relationships between specific entities.</p><pre name="ab8d" id="ab8d" class="graf graf--pre graf-after--p">MATCH (start:Entity), (end:Entity)<br>WHERE start.name = &quot;cytokines&quot; AND end.name = &quot;CD40L&quot;<br>MATCH p=allShortestPaths((start)-[:RELATIONSHIP*..5]-&gt;(end))<br>RETURN p LIMIT 25</pre><p name="dacb" id="dacb" class="graf graf--p graf-after--pre"><em class="markup--em markup--p-em">Results</em></p><figure name="9342" id="9342" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ZoFxS3j70haHFNUuAK8NMw.png" data-width="1077" data-height="627" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*ZoFxS3j70haHFNUuAK8NMw.png"><figcaption class="imageCaption">Indirect relations between biomedical entities. Image by the author.</figcaption></figure><p name="a24e" id="a24e" class="graf graf--p graf-after--figure">Interestingly, but not intended is that all the relationships in the result are <strong class="markup--strong markup--p-strong">INDIRECTED_UPREGULATOR.</strong> You could search for indirect patterns of any relationship types.</p><h4 name="4653" id="4653" class="graf graf--h4 graf-after--p">Next steps</h4><p name="27ac" id="27ac" class="graf graf--p graf-after--h4">There are a couple of options we have to enhance our NLP pipeline. The first that comes to mind is using entity linking or resolver models. Basically the entity resolver maps an entity to a target knowledge base like UMLS or Ensembl. By accurately linking entities to a target knowledge base we achieve two things:</p><ul class="postList"><li name="f678" id="f678" class="graf graf--li graf-after--p">Entity disambiguation</li><li name="265b" id="265b" class="graf graf--li graf-after--li">Ability to enrich our knowledge graph with external sources</li></ul><p name="bf56" id="bf56" class="graf graf--p graf-after--li">For example, I’ve found two nodes entities in our graph that might refer to the same real-world entity.</p><figure name="b1df" id="b1df" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ocJr3ZOzevO-HKC6XNtaNg.png" data-width="482" data-height="307" src="https://cdn-images-1.medium.com/max/800/1*ocJr3ZOzevO-HKC6XNtaNg.png"><figcaption class="imageCaption">Potential duplicates of the same entity. Image by the author.</figcaption></figure><p name="d15c" id="d15c" class="graf graf--p graf-after--figure">While John Snow Labs offers multiple Entity Resolution models, it takes a bit of domain knowledge to map entities to a specified target knowledge base efficiently. I’ve seen some real-world biomedical knowledge graphs that use multiple target knowledge bases like UMLS, OMIM, Entrez to cover all types of entities.</p><p name="bff5" id="bff5" class="graf graf--p graf-after--p">The second feature of using entity resolvers is that we can enrich our knowledge graph by using external biomedical sources. For example, one application would be to use a knowledge base to import existing knowledge and then find new relations between entities through NLP extraction.</p><p name="3489" id="3489" class="graf graf--p graf-after--p">Lastly, you could also use various graph machine learning libraries like the <a href="https://neo4j.com/docs/graph-data-science/current/algorithms/" data-href="https://neo4j.com/docs/graph-data-science/current/algorithms/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Neo4j GDS</a>, <a href="https://towardsdatascience.com/knowledge-graph-completion-with-pykeen-and-neo4j-6bca734edf43" data-href="https://towardsdatascience.com/knowledge-graph-completion-with-pykeen-and-neo4j-6bca734edf43" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">PyKEEN</a>, or even <a href="https://towardsdatascience.com/integrate-neo4j-with-pytorch-geometric-to-create-recommendations-21b0b7bc9aa" data-href="https://towardsdatascience.com/integrate-neo4j-with-pytorch-geometric-to-create-recommendations-21b0b7bc9aa" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">PyTorch Geometric</a> to predict new relationships.</p><p name="e9ea" id="e9ea" class="graf graf--p graf-after--p">Let me know if you find any exciting application using the combination of NLP pipelines and graph databases. Also let me know if you have some suggestions to improve any of the NLP or Knowledge Graph steps in this post. Thanks for reading!</p><p name="0a38" id="0a38" class="graf graf--p graf-after--p graf--trailing">As always, all the code is available as <a href="https://github.com/tomasonjo/blogs/blob/master/pubmed/Pubmed%20NLP.ipynb" data-href="https://github.com/tomasonjo/blogs/blob/master/pubmed/Pubmed%20NLP.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Google Colab notebook</a>.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@bratanic-tomaz" class="p-author h-card">Tomaz Bratanic</a> on <a href="https://medium.com/p/950d5ed4c758"><time class="dt-published" datetime="2022-03-10T17:05:02.987Z">March 10, 2022</time></a>.</p><p><a href="https://medium.com/@bratanic-tomaz/stay-in-touch-with-the-latest-medical-research-by-utilizing-spark-nlp-and-biomedical-knowledge-950d5ed4c758" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on November 5, 2023.</p></footer></article></body></html>