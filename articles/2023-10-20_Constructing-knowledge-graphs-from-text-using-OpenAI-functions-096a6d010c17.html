<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Constructing knowledge graphs from text using OpenAI functions</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Constructing knowledge graphs from text using OpenAI functions</h1>
</header>
<section data-field="subtitle" class="p-summary">
Seamlessy implement information extraction pipeline with LangChain and Neo4j
</section>
<section data-field="body" class="e-content">
<section name="0a8d" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="b968" id="b968" class="graf graf--h3 graf--leading graf--title">Constructing knowledge graphs from text using OpenAI functions</h3><h4 name="7c31" id="7c31" class="graf graf--h4 graf-after--h3 graf--subtitle">Seamlessy implement information extraction pipeline with LangChain and Neo4j</h4><p name="526a" id="526a" class="graf graf--p graf-after--h4">Extracting structured information from unstructured data like text has been around for some time and is nothing new. However, LLMs brought a significant shift to the field of information extraction. If before you needed a team of machine learning experts to curate datasets and train custom models, you only need access to an LLM nowadays. The barrier to entry has dropped significantly, making what was just a couple of years ago reserved for domain experts more accessible to even non-technical people.</p><figure name="28e7" id="28e7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*RYCIqV1Gfp18VkXfY411Xg.jpeg" data-width="545" data-height="275" src="https://cdn-images-1.medium.com/max/800/1*RYCIqV1Gfp18VkXfY411Xg.jpeg"><figcaption class="imageCaption">The goal of information extraction pipeline is to extract structured information from unstructured text. Image by the author.</figcaption></figure><p name="346e" id="346e" class="graf graf--p graf-after--figure">The image depicts the transformation of unstructured text into structured information. This process, labeled as the information extraction pipeline, results in a graph representation of information. The nodes represent key entities, while the connecting lines denote the relationships between these entities. Knowledge graphs are useful for <a href="https://medium.com/neo4j/knowledge-graphs-llms-multi-hop-question-answering-322113f53f51" data-href="https://medium.com/neo4j/knowledge-graphs-llms-multi-hop-question-answering-322113f53f51" class="markup--anchor markup--p-anchor" target="_blank">multi-hop question-answering</a>, <a href="https://medium.com/neo4j/knowledge-graphs-llms-real-time-graph-analytics-89b392eaaa95" data-href="https://medium.com/neo4j/knowledge-graphs-llms-real-time-graph-analytics-89b392eaaa95" class="markup--anchor markup--p-anchor" target="_blank">real-time analytics</a>, or when you want to <a href="https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/" data-href="https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">combine structured and unstructured data in a single database</a>.</p><p name="1906" id="1906" class="graf graf--p graf-after--p">While extracting structured information from text has been made more accessible due to LLMs, it is by no means a solved problem. In this blog post, we will use <a href="https://python.langchain.com/docs/modules/chains/how_to/openai_functions" data-href="https://python.langchain.com/docs/modules/chains/how_to/openai_functions" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">OpenAI functions in combination with LangChain</a> to construct a knowledge graph from a sample Wikipedia page. Along the way, we will discuss best practices as well as some limitations of current LLMs.</p><p name="4f4d" id="4f4d" class="graf graf--p graf-after--p">tldr; The code is available on <a href="https://github.com/tomasonjo/blogs/blob/master/llm/openaifunction_constructing_graph.ipynb" data-href="https://github.com/tomasonjo/blogs/blob/master/llm/openaifunction_constructing_graph.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GitHub</a>.</p><h3 name="f70d" id="f70d" class="graf graf--h3 graf-after--p">Neo4j Environment setup</h3><p name="ae42" id="ae42" class="graf graf--p graf-after--h3">You need to setup a Neo4j to follow along with the examples in this blog post. The easiest way is to start a free instance on <a href="https://neo4j.com/cloud/platform/aura-graph-database/" data-href="https://neo4j.com/cloud/platform/aura-graph-database/" class="markup--anchor markup--p-anchor" rel="noopener ugc nofollow noopener" target="_blank">Neo4j Aura</a>, which offers cloud instances of Neo4j database. Alternatively, you can also setup a local instance of the Neo4j database by downloading the <a href="https://neo4j.com/download/" data-href="https://neo4j.com/download/" class="markup--anchor markup--p-anchor" rel="noopener ugc nofollow noopener" target="_blank">Neo4j Desktop</a> application and creating a local database instance.</p><p name="04b8" id="04b8" class="graf graf--p graf-after--p">The following code will instantiate a LangChain wrapper to connect to Neo4j Database.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="108e" id="108e" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">from</span> langchain.graphs <span class="hljs-keyword">import</span> Neo4jGraph<br /><br />url = <span class="hljs-string">&quot;neo4j+s://databases.neo4j.io&quot;</span><br />username =<span class="hljs-string">&quot;neo4j&quot;</span><br />password = <span class="hljs-string">&quot;&quot;</span><br />graph = Neo4jGraph(<br />    url=url,<br />    username=username,<br />    password=password<br />)</span></pre><h3 name="c349" id="c349" class="graf graf--h3 graf-after--pre">Information extraction pipeline</h3><p name="6749" id="6749" class="graf graf--p graf-after--h3">A typical information extraction pipeline contains the following steps.</p><figure name="f662" id="f662" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*93ZK9-74dYv4eXY-Oe_bkA.png" data-width="601" data-height="381" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*93ZK9-74dYv4eXY-Oe_bkA.png"><figcaption class="imageCaption">Multiple steps of information extraction pipeline. Image by author.</figcaption></figure><p name="665a" id="665a" class="graf graf--p graf-after--figure">In the first step, we run the input text through a coreference resolution model. The coreference resolution is the task of finding all expressions that refer to a specific entity. Simply put, it links all the pronouns to the referred entity. In the named entity recognition part of the pipeline, we try to extract all the mentioned entities. The above example contains three entities: Tomaz, Blog, and Diagram. The next step is the entity disambiguation step, an essential but often overlooked part of an information extraction pipeline. Entity disambiguation is the process of accurately identifying and distinguishing between entities with similar names or references to ensure the correct entity is recognized in a given context. In the last step, the model tried to identify various relationships between entities. For example, it could locate the <strong class="markup--strong markup--p-strong">LIKES</strong> relationship between <strong class="markup--strong markup--p-strong">Tomaz</strong> and <strong class="markup--strong markup--p-strong">Blog</strong> entities.</p><h4 name="1869" id="1869" class="graf graf--h4 graf-after--p">Extracting structured information with OpenAI functions</h4><p name="8659" id="8659" class="graf graf--p graf-after--h4"><a href="https://openai.com/blog/function-calling-and-other-api-updates" data-href="https://openai.com/blog/function-calling-and-other-api-updates" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">OpenAI functions</a> are a great fit to extract structured information from natural language. The idea behind OpenAI functions is to have an LLM output a predefined JSON object with populated values. The predefined JSON object can be used as input to other functions in so-called RAG applications, or it can be used to extract predefined structured information from text.</p><p name="1a92" id="1a92" class="graf graf--p graf-after--p">In LangChain, you can<a href="https://python.langchain.com/docs/modules/chains/how_to/openai_functions" data-href="https://python.langchain.com/docs/modules/chains/how_to/openai_functions" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> pass a Pydantic class as description</a> of the desired JSON object of the OpenAI functions feature. Therefore, we will start by defining the desired structure of information we want to extract from text. LangChain already has <a href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/graphs/graph_document.py" data-href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/graphs/graph_document.py" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">definitions of nodes and relationship as Pydantic classes that we can reuse</a>.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="cbdd" id="cbdd" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span>(<span class="hljs-title class_ inherited__">Serializable</span>):<br />    <span class="hljs-string">&quot;&quot;&quot;Represents a node in a graph with associated properties.<br /><br />    Attributes:<br />        id (Union[str, int]): A unique identifier for the node.<br />        type (str): The type or label of the node, default is &quot;Node&quot;.<br />        properties (dict): Additional properties and metadata associated with the node.<br />    &quot;&quot;&quot;</span><br /><br />    <span class="hljs-built_in">id</span>: <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>]<br />    <span class="hljs-built_in">type</span>: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;Node&quot;</span><br />    properties: <span class="hljs-built_in">dict</span> = Field(default_factory=<span class="hljs-built_in">dict</span>)<br /><br /><br /><span class="hljs-keyword">class</span> <span class="hljs-title class_">Relationship</span>(<span class="hljs-title class_ inherited__">Serializable</span>):<br />    <span class="hljs-string">&quot;&quot;&quot;Represents a directed relationship between two nodes in a graph.<br /><br />    Attributes:<br />        source (Node): The source node of the relationship.<br />        target (Node): The target node of the relationship.<br />        type (str): The type of the relationship.<br />        properties (dict): Additional properties associated with the relationship.<br />    &quot;&quot;&quot;</span><br /><br />    source: Node<br />    target: Node<br />    <span class="hljs-built_in">type</span>: <span class="hljs-built_in">str</span><br />    properties: <span class="hljs-built_in">dict</span> = Field(default_factory=<span class="hljs-built_in">dict</span>)</span></pre><p name="d0d4" id="d0d4" class="graf graf--p graf-after--pre">Unfortunately, it turns out that OpenAI functions don’t currently support a dictionary object as a value. Therefore, we have to overwrite the <strong class="markup--strong markup--p-strong">properties</strong> definition to adhere to the limitations of the functions’ endpoint.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="0cfc" id="0cfc" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">from</span> langchain.graphs.graph_document <span class="hljs-keyword">import</span> (<br />    Node <span class="hljs-keyword">as</span> BaseNode,<br />    Relationship <span class="hljs-keyword">as</span> BaseRelationship<br />)<br /><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Dict</span>, <span class="hljs-type">Any</span>, <span class="hljs-type">Optional</span><br /><span class="hljs-keyword">from</span> langchain.pydantic_v1 <span class="hljs-keyword">import</span> Field, BaseModel<br /><br /><span class="hljs-keyword">class</span> <span class="hljs-title class_">Property</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br />  <span class="hljs-string">&quot;&quot;&quot;A single property consisting of key and value&quot;&quot;&quot;</span><br />  key: <span class="hljs-built_in">str</span> = Field(..., description=<span class="hljs-string">&quot;key&quot;</span>)<br />  value: <span class="hljs-built_in">str</span> = Field(..., description=<span class="hljs-string">&quot;value&quot;</span>)<br /><br /><span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span>(<span class="hljs-title class_ inherited__">BaseNode</span>):<br />    properties: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[Property]] = Field(<br />        <span class="hljs-literal">None</span>, description=<span class="hljs-string">&quot;List of node properties&quot;</span>)<br /><br /><span class="hljs-keyword">class</span> <span class="hljs-title class_">Relationship</span>(<span class="hljs-title class_ inherited__">BaseRelationship</span>):<br />    properties: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[Property]] = Field(<br />        <span class="hljs-literal">None</span>, description=<span class="hljs-string">&quot;List of relationship properties&quot;</span><br />    )</span></pre><p name="6d12" id="6d12" class="graf graf--p graf-after--pre">Here, we have overwritten the properties value to be a list of <strong class="markup--strong markup--p-strong">Property</strong> classes instead of a dictionary to overcome the limitations of the API. Because you can only pass a single object to the API, we can to combine the nodes and relationships in a single class called <strong class="markup--strong markup--p-strong">KnowledgeGraph</strong>.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="7941" id="7941" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">class</span> <span class="hljs-title class_">KnowledgeGraph</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br />    <span class="hljs-string">&quot;&quot;&quot;Generate a knowledge graph with entities and relationships.&quot;&quot;&quot;</span><br />    nodes: <span class="hljs-type">List</span>[Node] = Field(<br />        ..., description=<span class="hljs-string">&quot;List of nodes in the knowledge graph&quot;</span>)<br />    rels: <span class="hljs-type">List</span>[Relationship] = Field(<br />        ..., description=<span class="hljs-string">&quot;List of relationships in the knowledge graph&quot;</span><br />    )</span></pre><p name="47f9" id="47f9" class="graf graf--p graf-after--pre">The only thing left is to do a bit of prompt engineering and we are good to go. How I usually go about prompt engineering is the following:</p><ul class="postList"><li name="08b8" id="08b8" class="graf graf--li graf-after--p">Iterate over prompt and improve results using natural language</li><li name="0ff0" id="0ff0" class="graf graf--li graf-after--li">If something doesn’t work as intended, ask ChatGPT to make it clearer for an LLM to understand the task</li><li name="88bc" id="88bc" class="graf graf--li graf-after--li">Finally, when the prompt has all the instructions needed, ask ChatGPT to summarize the instructions in a markdown format, saving on tokens and perhaps having more clear instructions</li></ul><p name="58a6" id="58a6" class="graf graf--p graf-after--li">I specifically chose the markdown format as I have seen somewhere that OpenAI models respond better to markdown syntax in prompts, and it seems to be at least plausible from my experience.</p><p name="cbc7" id="cbc7" class="graf graf--p graf-after--p">Iterating over prompt engineering, I came up with the following system prompt for an information extraction pipeline.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="1bca" id="1bca" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">llm = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo-16k&quot;</span>, temperature=<span class="hljs-number">0</span>)<br /><br /><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_extraction_chain</span>(<span class="hljs-params"><br />    allowed_nodes: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,<br />    allowed_rels: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span><br />    </span>):<br />    prompt = ChatPromptTemplate.from_messages(<br />    [(<br />      <span class="hljs-string">&quot;system&quot;</span>,<br />      <span class="hljs-string">f&quot;&quot;&quot;# Knowledge Graph Instructions for GPT-4<br />## 1. Overview<br />You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.<br />- **Nodes** represent entities and concepts. They&#x27;re akin to Wikipedia nodes.<br />- The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.<br />## 2. Labeling Nodes<br />- **Consistency**: Ensure you use basic or elementary types for node labels.<br />  - For example, when you identify an entity representing a person, always label it as **&quot;person&quot;**. Avoid using more specific terms like &quot;mathematician&quot; or &quot;scientist&quot;.<br />- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.<br /><span class="hljs-subst">{<span class="hljs-string">&#x27;- **Allowed Node Labels:**&#x27;</span> + <span class="hljs-string">&quot;, &quot;</span>.join(allowed_nodes) <span class="hljs-keyword">if</span> allowed_nodes <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;&quot;</span>}</span><br /><span class="hljs-subst">{<span class="hljs-string">&#x27;- **Allowed Relationship Types**:&#x27;</span> + <span class="hljs-string">&quot;, &quot;</span>.join(allowed_rels) <span class="hljs-keyword">if</span> allowed_rels <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;&quot;</span>}</span><br />## 3. Handling Numerical Data and Dates<br />- Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.<br />- **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.<br />- **Property Format**: Properties must be in a key-value format.<br />- **Quotation Marks**: Never use escaped single or double quotes within property values.<br />- **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.<br />## 4. Coreference Resolution<br />- **Maintain Entity Consistency**: When extracting entities, it&#x27;s vital to ensure consistency.<br />If an entity, such as &quot;John Doe&quot;, is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., &quot;Joe&quot;, &quot;he&quot;), <br />always use the most complete identifier for that entity throughout the knowledge graph. In this example, use &quot;John Doe&quot; as the entity ID.  <br />Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial. <br />## 5. Strict Compliance<br />Adhere to the rules strictly. Non-compliance will result in termination.&quot;&quot;&quot;</span>),<br />        (<span class="hljs-string">&quot;human&quot;</span>, <span class="hljs-string">&quot;Use the given format to extract information from the following input: {input}&quot;</span>),<br />        (<span class="hljs-string">&quot;human&quot;</span>, <span class="hljs-string">&quot;Tip: Make sure to answer in the correct format&quot;</span>),<br />    ])<br />    <span class="hljs-keyword">return</span> create_structured_output_chain(KnowledgeGraph, llm, prompt, verbose=<span class="hljs-literal">False</span>)</span></pre><p name="c947" id="c947" class="graf graf--p graf-after--pre">You can see that we are using the 16k version of the GPT-3.5 model. The main reason is that the OpenAI function output is a structured JSON object, and structured JSON syntax adds a lot of token overhead to the result. Essentially, you are paying for the convenience of structured output in increased token space.</p><p name="a1ec" id="a1ec" class="graf graf--p graf-after--p">Besides the general instructions, I have also added the option to limit which node or relationship types should be extracted from text. You’ll see through examples why this might come in handy.</p><p name="ebad" id="ebad" class="graf graf--p graf-after--p">We have the Neo4j connection and LLM prompt ready, which means we can define the information extraction pipeline as a single function.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="a882" id="a882" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">def</span> <span class="hljs-title function_">extract_and_store_graph</span>(<span class="hljs-params"><br />    document: Document,<br />    nodes:<span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,<br />    rels:<span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]]=<span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-literal">None</span>:<br />    <span class="hljs-comment"># Extract graph data using OpenAI functions</span><br />    extract_chain = get_extraction_chain(nodes, rels)<br />    data = extract_chain.run(document.page_content)<br />    <span class="hljs-comment"># Construct a graph document</span><br />    graph_document = GraphDocument(<br />      nodes = [map_to_base_node(node) <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> data.nodes],<br />      relationships = [map_to_base_relationship(rel) <span class="hljs-keyword">for</span> rel <span class="hljs-keyword">in</span> data.rels],<br />      source = document<br />    )<br />    <span class="hljs-comment"># Store information into a graph</span><br />    graph.add_graph_documents([graph_document])</span></pre><p name="ef27" id="ef27" class="graf graf--p graf-after--pre">The function takes in a LangChain document as well as optional nodes and relationship parameters, which are used to limit the types of objects we want the LLM to identify and extract. A month or so ago, we added the <code class="markup--code markup--p-code">add_graph_documents</code> method the Neo4j graph object, which we can utilize here to seamlessly import the graph.</p><h4 name="9a5c" id="9a5c" class="graf graf--h4 graf-after--p">Evaluation</h4><p name="ce26" id="ce26" class="graf graf--p graf-after--h4">We will extract information from the Walt Disney Wikipedia page and construct a knowledge graph to test the pipeline. Here, we will utilize the Wikipedia loader and text chunking modules provided by LangChain.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="6fde" id="6fde" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> WikipediaLoader<br /><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> TokenTextSplitter<br /><br /><span class="hljs-comment"># Read the wikipedia article</span><br />raw_documents = WikipediaLoader(query=<span class="hljs-string">&quot;Walt Disney&quot;</span>).load()<br /><span class="hljs-comment"># Define chunking strategy</span><br />text_splitter = TokenTextSplitter(chunk_size=<span class="hljs-number">2048</span>, chunk_overlap=<span class="hljs-number">24</span>)<br /><br /><span class="hljs-comment"># Only take the first the raw_documents</span><br />documents = text_splitter.split_documents(raw_documents[:<span class="hljs-number">3</span>])</span></pre><p name="59c5" id="59c5" class="graf graf--p graf-after--pre">You might have noticed that we use a relatively large <code class="markup--code markup--p-code">chunk_size</code> value. The reason is that we want to provide as much context as possible around a single sentence in order for the coreference resolution part to work as best as possible. Remember, the coreference step will only work if the entity and its reference appear in the same chunk; otherwise, the LLM doesn’t have enough information to link the two.</p><p name="b767" id="b767" class="graf graf--p graf-after--p">Now we can go ahead and run the documents through the information extraction pipeline.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="72ae" id="72ae" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br /><br /><span class="hljs-keyword">for</span> i, d <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">enumerate</span>(documents), total=<span class="hljs-built_in">len</span>(documents)):<br />    extract_and_store_graph(d)</span></pre><p name="e0e5" id="e0e5" class="graf graf--p graf-after--pre">The process takes around 5 minutes, which is relatively slow. Therefore, you would probably want parallel API calls in production to deal with this problem and achieve some sort of scalability.</p><p name="cc3f" id="cc3f" class="graf graf--p graf-after--p">Let’s first look at the types of nodes and relationships the LLM identified.</p><figure name="5917" id="5917" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*OCjG5oY6DyOnLuo1_N4OlA.png" data-width="462" data-height="657" src="https://cdn-images-1.medium.com/max/800/1*OCjG5oY6DyOnLuo1_N4OlA.png"></figure><p name="45a7" id="45a7" class="graf graf--p graf-after--figure">Since the graph schema is not provided, the LLM decides on the fly what types of node labels and relationship types it will use. For example, we can observe that there are <strong class="markup--strong markup--p-strong">Company</strong> and <strong class="markup--strong markup--p-strong">Organization</strong> node labels. Those two things are probably semantically similar or identical, so we would want to have only a single node label representing the two. This problem is more obvious with relationship types. For example, we have <strong class="markup--strong markup--p-strong">CO-FOUNDER</strong> and <strong class="markup--strong markup--p-strong">COFOUNDEROF</strong> relationships as well as <strong class="markup--strong markup--p-strong">DEVELOPER</strong> and <strong class="markup--strong markup--p-strong">DEVELOPEDBY</strong>.</p><p name="1cdb" id="1cdb" class="graf graf--p graf-after--p">For any more serious project, you should define the node labels and relationship types the LLM should extract. Luckily, we have added the option to limit the types in the prompt by passing additional parameters.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="083c" id="083c" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Specify which node labels should be extracted by the LLM</span><br />allowed_nodes = [<span class="hljs-string">&quot;Person&quot;</span>, <span class="hljs-string">&quot;Company&quot;</span>, <span class="hljs-string">&quot;Location&quot;</span>, <span class="hljs-string">&quot;Event&quot;</span>, <span class="hljs-string">&quot;Movie&quot;</span>, <span class="hljs-string">&quot;Service&quot;</span>, <span class="hljs-string">&quot;Award&quot;</span>]<br /><br /><span class="hljs-keyword">for</span> i, d <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">enumerate</span>(documents), total=<span class="hljs-built_in">len</span>(documents)):<br />    extract_and_store_graph(d, allowed_nodes)</span></pre><p name="b031" id="b031" class="graf graf--p graf-after--pre">In this example, I have only limited the node labels, but you can easily limit the relationship types by passing another parameter to the <code class="markup--code markup--p-code">extract_and_store_graph</code> function.</p><p name="e3b4" id="e3b4" class="graf graf--p graf-after--p">The visualization of the extracted subgraph has the following structure.</p><figure name="adea" id="adea" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*mEipkYmePMYvX4t5tU8u2w.png" data-width="1101" data-height="792" src="https://cdn-images-1.medium.com/max/800/1*mEipkYmePMYvX4t5tU8u2w.png"></figure><p name="8042" id="8042" class="graf graf--p graf-after--figure">The graph turned out better than expected (after five iterations :) ). I couldn’t catch the whole graph nicely in the visualization, but you can explore it on your own in Neo4j Browser other tools.</p><h4 name="5a92" id="5a92" class="graf graf--h4 graf-after--p">Entity disambiguation</h4><p name="4aa9" id="4aa9" class="graf graf--p graf-after--h4">One thing I should mention is that we partly skipped entity disambiguation part. We used a large chunk size and added a specific instruction for coreference resolution and entity disambiguation in the system prompt. However, since each chunk is processed separately, there is no way to ensure consistency of entities between different text chunks. For example, you could end up with two nodes representing the same person.</p><figure name="daf3" id="daf3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*PHsfndcMjOMoAdUAx8IJrw.png" data-width="472" data-height="302" src="https://cdn-images-1.medium.com/max/800/1*PHsfndcMjOMoAdUAx8IJrw.png"><figcaption class="imageCaption">Multiple nodes representing the same entity.</figcaption></figure><p name="d461" id="d461" class="graf graf--p graf-after--figure">In this example, Walt Disney and Walter Elias Disney refer to the same real-world person. The entity disambiguation problem is nothing new and there has been various solution proposed to solve it:</p><ul class="postList"><li name="1636" id="1636" class="graf graf--li graf-after--p">Using <a href="https://wikifier.org/about.html" data-href="https://wikifier.org/about.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">entity linking</a> or <a href="https://github.com/SapienzaNLP/extend" data-href="https://github.com/SapienzaNLP/extend" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">entity disambiguation</a> NLP models</li><li name="6f03" id="6f03" class="graf graf--li graf-after--li">Doing a <a href="https://medium.com/neo4j/creating-a-knowledge-graph-from-video-transcripts-with-gpt-4-52d7c7b9f32c" data-href="https://medium.com/neo4j/creating-a-knowledge-graph-from-video-transcripts-with-gpt-4-52d7c7b9f32c" class="markup--anchor markup--li-anchor" target="_blank">second pass through an LLM</a> and asking it to perform entity disambiguation</li><li name="74ce" id="74ce" class="graf graf--li graf-after--li"><a href="https://neo4j.com/developer-blog/exploring-supervised-entity-resolution-in-neo4j/" data-href="https://neo4j.com/developer-blog/exploring-supervised-entity-resolution-in-neo4j/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Graph-based approaches</a></li></ul><p name="3e85" id="3e85" class="graf graf--p graf-after--li">Which solution you should use depends on your domain and use case. However, have in mind that entity disambiguation step should not be overlooked as it can have a significant impact on the accuracy and effectiveness of your RAG applications.</p><h4 name="838f" id="838f" class="graf graf--h4 graf-after--p">Rag Application</h4><p name="d420" id="d420" class="graf graf--p graf-after--h4">The last thing we will do is show you how you can browse information in a knowledge graph by constructing Cypher statements. Cypher is a structured query language used to work with graph databases, similar to how SQL is used for relational databases. LangChain has a <a href="https://medium.com/neo4j/langchain-cypher-search-tips-tricks-f7c9e9abca4d" data-href="https://medium.com/neo4j/langchain-cypher-search-tips-tricks-f7c9e9abca4d" class="markup--anchor markup--p-anchor" target="_blank">GraphCypherQAChain</a> that reads the schema of the graph and constructs appropriate Cypher statements based on the user input.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="be98" id="be98" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Query the knowledge graph in a RAG application</span><br /><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> GraphCypherQAChain<br /><br />graph.refresh_schema()<br /><br />cypher_chain = GraphCypherQAChain.from_llm(<br />    graph=graph,<br />    cypher_llm=ChatOpenAI(temperature=<span class="hljs-number">0</span>, model=<span class="hljs-string">&quot;gpt-4&quot;</span>),<br />    qa_llm=ChatOpenAI(temperature=<span class="hljs-number">0</span>, model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>),<br />    validate_cypher=<span class="hljs-literal">True</span>, <span class="hljs-comment"># Validate relationship directions</span><br />    verbose=<span class="hljs-literal">True</span><br />)<br />cypher_chain.run(<span class="hljs-string">&quot;When was Walter Elias Disney born?&quot;</span>)</span></pre><p name="2504" id="2504" class="graf graf--p graf-after--pre"><em class="markup--em markup--p-em">Which results in the following:</em></p><figure name="eaed" id="eaed" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*CTF2gfNwx4v7V-0qM4s6uw.png" data-width="565" data-height="159" src="https://cdn-images-1.medium.com/max/800/1*CTF2gfNwx4v7V-0qM4s6uw.png"></figure><h4 name="85d7" id="85d7" class="graf graf--h4 graf-after--figure">Summary</h4><p name="8a15" id="8a15" class="graf graf--p graf-after--h4">Knowledge graphs are a great fit when you need a combination of structured and structured data to power your RAG applications. In this blog post, you have learned how to construct a knowledge graph in Neo4j on an arbitrary text using OpenAI functions. OpenAI functions provide the convenience of neatly structured outputs, making them an ideal fit for extracting structured information. To have a great experience constructing graphs with LLMs, make sure to define the graph schema as detailed as possible and make sure you add an entity disambiguation step after the extraction.</p><p name="1aa7" id="1aa7" class="graf graf--p graf-after--p">If you are eager to learn more about building AI applications with graphs, join us at the <a href="https://neo4j.registration.goldcast.io/events/6fb85147-ca27-4310-9dec-cb345c53bd6f?ref=blog.langchain.dev" data-href="https://neo4j.registration.goldcast.io/events/6fb85147-ca27-4310-9dec-cb345c53bd6f?ref=blog.langchain.dev" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">NODES, online, 24h conference</a> organized by Neo4j on October 26th, 2023.</p><p name="50fc" id="50fc" class="graf graf--p graf-after--p graf--trailing">The code is available on <a href="https://github.com/tomasonjo/blogs/blob/master/llm/openaifunction_constructing_graph.ipynb" data-href="https://github.com/tomasonjo/blogs/blob/master/llm/openaifunction_constructing_graph.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GitHub</a>.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@bratanic-tomaz" class="p-author h-card">Tomaz Bratanic</a> on <a href="https://medium.com/p/096a6d010c17"><time class="dt-published" datetime="2023-10-20T14:00:02.421Z">October 20, 2023</time></a>.</p><p><a href="https://medium.com/@bratanic-tomaz/constructing-knowledge-graphs-from-text-using-openai-functions-096a6d010c17" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on November 5, 2023.</p></footer></article></body></html>